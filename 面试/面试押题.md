一份Go语言相关面试题，涵盖Go语言基础、Gin框架、数据库优化、Redis、消息队列、微服务、Docker和高性能系统设计等内容。每部分包含基础题和进阶题，尽量覆盖实际应用场景和问题解决能力。

---

### 1. Go语言基础
#### 基础题
1. **Go语言的并发模型是什么？goroutine和channel是如何工作的？**
   - 要求：解释goroutine的轻量级线程特性，channel的通信机制，并举例说明如何使用goroutine和channel实现并发任务。
   
   **答案：**
   Go语言的并发模型基于CSP（Communicating Sequential Processes）理论，主要通过goroutine和channel实现。

   **goroutine特性：**
   - 轻量级线程，初始栈大小仅2KB
   - 由Go运行时调度，非操作系统线程
   - 可以轻松创建上万个goroutine
   - 支持自动扩展栈空间

   **channel特性：**
   - 类型安全的通信机制
   - 支持阻塞和非阻塞操作
   - 可以用于goroutine之间的同步
   - 支持select多路复用

   **代码示例：**
   ```go
   // 并发下载多个URL的内容
   func fetchURLs(urls []string) []string {
       results := make([]string, len(urls))
       ch := make(chan struct{url string; content string; index int})
       
       for i, url := range urls {
           go func(url string, index int) {
               resp, err := http.Get(url)
               if err != nil {
                   ch <- struct{url string; content string; index int}{url, err.Error(), index}
                   return
               }
               defer resp.Body.Close()
               body, _ := ioutil.ReadAll(resp.Body)
               ch <- struct{url string; content string; index int}{url, string(body), index}
           }(url, i)
       }
       
       for range urls {
           result := <-ch
           results[result.index] = result.content
       }
       
       return results
   }
   ```

2. **Go的内存管理机制是怎样的？垃圾回收（GC）的工作原理是什么？**
   - 要求：描述Go的垃圾回收算法（如标记-清除），以及如何减少GC对性能的影响。
   
   **答案：**
   Go的内存管理采用分代式垃圾回收算法，主要特点如下：

   **内存分配：**
   - 使用TCMalloc（Thread-Caching Malloc）算法
   - 将内存分为多个大小类别
   - 使用mcache、mcentral、mheap三级缓存
   - 支持内存池复用

   **垃圾回收：**
   - 采用三色标记法
   - 并发标记和清除
   - 写屏障保证并发安全
   - 支持GC调优参数

   **减少GC影响的实践：**
   ```go
   // 1. 使用对象池复用对象
   var userPool = sync.Pool{
       New: func() interface{} {
           return &User{}
       },
   }
   
   // 2. 避免频繁创建临时对象
   func processData(data []byte) {
       // 错误方式：每次循环创建新的string
       for _, b := range data {
           s := string(b) // 创建临时string
           // ...
       }
       
       // 正确方式：复用string
       var s string
       for _, b := range data {
           s = string(b)
           // ...
       }
   }
   
   // 3. 使用切片预分配容量
   func createSlice() {
       // 错误方式：频繁扩容
       s := make([]int, 0)
       for i := 0; i < 1000; i++ {
           s = append(s, i)
       }
       
       // 正确方式：预分配容量
       s := make([]int, 0, 1000)
       for i := 0; i < 1000; i++ {
           s = append(s, i)
       }
   }
   ```

3. **interface{}在Go中的作用是什么？如何实现类型断言和类型切换？**
   - 要求：提供代码示例，展示interface{}的用法和类型断言的场景。
   
   **答案：**
   interface{}是Go语言中的空接口，可以存储任意类型的值。

   **类型断言：**
   ```go
   // 1. 基本类型断言
   func processValue(v interface{}) {
       if str, ok := v.(string); ok {
           fmt.Println("字符串:", str)
       } else if num, ok := v.(int); ok {
           fmt.Println("数字:", num)
       }
   }
   
   // 2. 类型切换
   func processValueWithSwitch(v interface{}) {
       switch val := v.(type) {
       case string:
           fmt.Println("字符串:", val)
       case int:
           fmt.Println("数字:", val)
       case []interface{}:
           fmt.Println("切片:", val)
       default:
           fmt.Println("未知类型")
       }
   }
   
   // 3. 实际应用：JSON解析
   func parseJSON(data []byte) {
       var result interface{}
       if err := json.Unmarshal(data, &result); err != nil {
           return
       }
       
       switch v := result.(type) {
       case map[string]interface{}:
           for key, value := range v {
               fmt.Printf("%s: %v\n", key, value)
           }
       case []interface{}:
           for i, item := range v {
               fmt.Printf("Item %d: %v\n", i, item)
           }
       }
   }
   ```

4. **defer关键字的作用是什么？它的执行顺序如何？**
   - 要求：结合实际场景（如文件操作）说明defer的用途，分析多defer语句的执行顺序。
   
   **答案：**
   defer用于延迟函数的执行，直到当前函数返回。

   **执行顺序：**
   - 多个defer按照LIFO（后进先出）顺序执行
   - defer语句中的参数在声明时求值
   - defer可以修改命名返回值

   **实际应用：**
   ```go
   // 1. 文件操作
   func readFile(path string) (string, error) {
       f, err := os.Open(path)
       if err != nil {
           return "", err
       }
       defer f.Close() // 确保文件最终被关闭
       
       content, err := ioutil.ReadAll(f)
       if err != nil {
           return "", err
       }
       return string(content), nil
   }
   
   // 2. 数据库事务
   func processTransaction(db *sql.DB) error {
       tx, err := db.Begin()
       if err != nil {
           return err
       }
       defer func() {
           if p := recover(); p != nil {
               tx.Rollback()
               panic(p)
           }
       }()
       
       // 执行事务操作
       if err := doSomething(tx); err != nil {
           tx.Rollback()
           return err
       }
       
       return tx.Commit()
   }
   
   // 3. 性能分析
   func profileFunction() {
       defer func(start time.Time) {
           fmt.Printf("函数执行时间: %v\n", time.Since(start))
       }(time.Now())
       
       // 函数主体
       time.Sleep(100 * time.Millisecond)
   }
   ```

#### 进阶题
5. **如何进行Go程序的性能调优？有哪些常用工具和方法？**
   - 要求：介绍pprof、trace等工具，结合一个实际例子（如CPU密集型任务）说明调优步骤。
   
   **答案：**
   Go程序的性能调优主要从以下几个方面进行：

   **1. 使用pprof进行性能分析**
   ```go
   // 在代码中添加性能分析
   import _ "net/http/pprof"
   
   func main() {
       go func() {
           log.Println(http.ListenAndServe("localhost:6060", nil))
       }()
       // 你的应用代码
   }
   
   // 使用命令行工具分析
   // go tool pprof http://localhost:6060/debug/pprof/heap
   // go tool pprof http://localhost:6060/debug/pprof/profile
   ```

   **2. 使用trace进行并发分析**
   ```go
   import "runtime/trace"
   
   func main() {
       f, err := os.Create("trace.out")
       if err != nil {
           log.Fatal(err)
       }
       defer f.Close()
       
       err = trace.Start(f)
       if err != nil {
           log.Fatal(err)
       }
       defer trace.Stop()
       
       // 你的应用代码
   }
   ```

   **3. 实际优化示例：优化CPU密集型任务**
   ```go
   // 优化前：串行处理
   func processData(data []int) []int {
       result := make([]int, len(data))
       for i, v := range data {
           result[i] = heavyComputation(v)
       }
       return result
   }
   
   // 优化后：并行处理
   func processDataOptimized(data []int) []int {
       result := make([]int, len(data))
       var wg sync.WaitGroup
       workers := runtime.NumCPU()
       chunkSize := len(data) / workers
       
       for i := 0; i < workers; i++ {
           wg.Add(1)
           start := i * chunkSize
           end := start + chunkSize
           if i == workers-1 {
               end = len(data)
           }
           
           go func(start, end int) {
               defer wg.Done()
               for j := start; j < end; j++ {
                   result[j] = heavyComputation(data[j])
               }
           }(start, end)
       }
       
       wg.Wait()
       return result
   }
   ```

6. **goroutine泄漏可能发生在哪些场景？如何检测和避免？**
   - 要求：举例说明goroutine泄漏的典型场景，并介绍使用context或工具检测泄漏的方法。
   
   **答案：**
   goroutine泄漏是Go程序中常见的问题，主要发生在以下场景：

   **1. 典型泄漏场景**
   ```go
   // 场景1：未正确关闭channel
   func leakyFunction() {
       ch := make(chan int)
       go func() {
           ch <- 1 // 发送数据
       }()
       // 没有接收者，goroutine阻塞
   }
   
   // 场景2：无限循环
   func leakyLoop() {
       for {
           go func() {
               // 无限循环的goroutine
           }()
       }
   }
   
   // 场景3：未使用context控制超时
   func leakyTimeout() {
       for {
           go func() {
               // 可能永远阻塞的操作
               time.Sleep(time.Hour)
           }()
       }
   }
   ```

   **2. 正确的实现方式**
   ```go
   // 使用context控制超时
   func properTimeout(ctx context.Context) {
       for {
           select {
           case <-ctx.Done():
               return
           default:
               go func() {
                   // 使用context控制超时
                   ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
                   defer cancel()
                   
                   // 执行操作
                   doSomething(ctx)
               }()
           }
       }
   }
   
   // 使用sync.WaitGroup确保goroutine完成
   func properWaitGroup() {
       var wg sync.WaitGroup
       for i := 0; i < 10; i++ {
           wg.Add(1)
           go func() {
               defer wg.Done()
               // 执行操作
           }()
       }
       wg.Wait()
   }
   ```

   **3. 检测goroutine泄漏**
   ```go
   // 使用runtime.NumGoroutine()监控
   func monitorGoroutines() {
       go func() {
           for {
               time.Sleep(time.Second)
               fmt.Printf("当前goroutine数量: %d\n", runtime.NumGoroutine())
           }
       }()
   }
   ```

7. **Go的slice和map在并发场景下的安全性如何？如何实现安全的并发访问？**
   - 要求：分析slice和map的线程安全性问题，介绍sync.Mutex或sync.RWMutex的使用。
   
   **答案：**
   Go的slice和map在并发场景下不是线程安全的，需要额外的同步机制。

   **1. 并发安全的slice操作**
   ```go
   // 使用互斥锁保护slice
   type SafeSlice struct {
       sync.RWMutex
       items []int
   }
   
   func (s *SafeSlice) Append(item int) {
       s.Lock()
       defer s.Unlock()
       s.items = append(s.items, item)
   }
   
   func (s *SafeSlice) Get(index int) (int, error) {
       s.RLock()
       defer s.RUnlock()
       if index < 0 || index >= len(s.items) {
           return 0, errors.New("index out of range")
       }
       return s.items[index], nil
   }
   ```

   **2. 并发安全的map操作**
   ```go
   // 使用sync.Map（推荐）
   var safeMap sync.Map
   
   func main() {
       // 存储
       safeMap.Store("key", "value")
       
       // 读取
       if value, ok := safeMap.Load("key"); ok {
           fmt.Println(value)
       }
       
       // 删除
       safeMap.Delete("key")
       
       // 原子操作
       safeMap.LoadOrStore("key", "value")
   }
   
   // 使用互斥锁保护map
   type SafeMap struct {
       sync.RWMutex
       items map[string]interface{}
   }
   
   func (m *SafeMap) Set(key string, value interface{}) {
       m.Lock()
       defer m.Unlock()
       m.items[key] = value
   }
   
   func (m *SafeMap) Get(key string) (interface{}, bool) {
       m.RLock()
       defer m.RUnlock()
       value, ok := m.items[key]
       return value, ok
   }
   ```

   **3. 实际应用示例：并发安全的缓存**
   ```go
   type Cache struct {
       sync.RWMutex
       items    map[string]interface{}
       maxSize  int
   }
   
   func NewCache(maxSize int) *Cache {
       return &Cache{
           items:   make(map[string]interface{}),
           maxSize: maxSize,
       }
   }
   
   func (c *Cache) Set(key string, value interface{}) {
       c.Lock()
       defer c.Unlock()
       
       // 检查容量
       if len(c.items) >= c.maxSize {
           // 实现LRU或其他淘汰策略
           c.evict()
       }
       
       c.items[key] = value
   }
   
   func (c *Cache) Get(key string) (interface{}, bool) {
       c.RLock()
       defer c.RUnlock()
       value, ok := c.items[key]
       return value, ok
   }
   
   func (c *Cache) evict() {
       // 实现淘汰策略
   }
   ```

---

### 2. Gin框架
#### 基础题
11. **Gin框架中如何实现一个简单的RESTful API？**
    - 要求：提供一个简单的代码示例，包含GET和POST路由的实现。
    
    **答案：**
    下面是一个完整的RESTful API示例，包含用户管理的CRUD操作：

    ```go
    // 用户模型
    type User struct {
        ID       uint   `json:"id"`
        Username string `json:"username"`
        Email    string `json:"email"`
    }
    
    // 主程序
    func main() {
        r := gin.Default()
        
        // GET 获取用户列表
        r.GET("/users", func(c *gin.Context) {
            users := []User{
                {ID: 1, Username: "user1", Email: "user1@example.com"},
                {ID: 2, Username: "user2", Email: "user2@example.com"},
            }
            c.JSON(http.StatusOK, users)
        })
        
        // GET 获取单个用户
        r.GET("/users/:id", func(c *gin.Context) {
            id := c.Param("id")
            user := User{ID: 1, Username: "user1", Email: "user1@example.com"}
            c.JSON(http.StatusOK, user)
        })
        
        // POST 创建用户
        r.POST("/users", func(c *gin.Context) {
            var user User
            if err := c.ShouldBindJSON(&user); err != nil {
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
            }
            // 处理用户创建逻辑
            c.JSON(http.StatusCreated, user)
        })
        
        // PUT 更新用户
        r.PUT("/users/:id", func(c *gin.Context) {
            id := c.Param("id")
            var user User
            if err := c.ShouldBindJSON(&user); err != nil {
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
            }
            // 处理用户更新逻辑
            c.JSON(http.StatusOK, user)
        })
        
        // DELETE 删除用户
        r.DELETE("/users/:id", func(c *gin.Context) {
            id := c.Param("id")
            // 处理用户删除逻辑
            c.JSON(http.StatusOK, gin.H{"message": "用户已删除"})
        })
        
        r.Run(":8080")
    }
    ```

12. **Gin中间件的用途是什么？如何编写一个自定义中间件？**
    - 要求：说明中间件的作用（如日志、认证），并编写一个记录请求时间的中间件代码。
    
    **答案：**
    Gin中间件用于处理请求的预处理和后处理，常见用途包括：
    - 日志记录
    - 认证授权
    - 错误处理
    - 请求限流
    - 跨域处理

    **自定义中间件示例：**
    ```go
    // 1. 请求时间记录中间件
    func RequestTime() gin.HandlerFunc {
        return func(c *gin.Context) {
            start := time.Now()
            
            // 处理请求
            c.Next()
            
            // 请求处理完成后
            duration := time.Since(start)
            log.Printf("请求路径: %s, 处理时间: %v", c.Request.URL.Path, duration)
        }
    }
    
    // 2. 认证中间件
    func AuthMiddleware() gin.HandlerFunc {
        return func(c *gin.Context) {
            token := c.GetHeader("Authorization")
            if token == "" {
                c.JSON(http.StatusUnauthorized, gin.H{"error": "未授权访问"})
                c.Abort()
                return
            }
            
            // 验证token
            if !validateToken(token) {
                c.JSON(http.StatusUnauthorized, gin.H{"error": "无效的token"})
                c.Abort()
                return
            }
            
            c.Next()
        }
    }
    
    // 3. 错误恢复中间件
    func RecoveryMiddleware() gin.HandlerFunc {
        return func(c *gin.Context) {
            defer func() {
                if err := recover(); err != nil {
                    c.JSON(http.StatusInternalServerError, gin.H{
                        "error": "服务器内部错误",
                    })
                    c.Abort()
                }
            }()
            c.Next()
        }
    }
    
    // 使用中间件
    func main() {
        r := gin.New()
        
        // 使用内置中间件
        r.Use(gin.Logger())
        r.Use(gin.Recovery())
        
        // 使用自定义中间件
        r.Use(RequestTime())
        r.Use(AuthMiddleware())
        
        // 路由
        r.GET("/ping", func(c *gin.Context) {
            c.JSON(200, gin.H{"message": "pong"})
        })
        
        r.Run(":8080")
    }
    ```

13. **Gin的路由分组（Group）如何使用？有什么实际场景？**
    - 要求：展示路由分组的代码，并说明在API版本控制中的应用。
    
    **答案：**
    路由分组可以更好地组织API结构，常见应用场景包括：
    - API版本控制
    - 权限分组
    - 功能模块分组

    **示例代码：**
    ```go
    func main() {
        r := gin.Default()
        
        // API版本分组
        v1 := r.Group("/api/v1")
        {
            // 用户相关路由
            users := v1.Group("/users")
            {
                users.GET("", listUsers)
                users.POST("", createUser)
                users.GET("/:id", getUser)
                users.PUT("/:id", updateUser)
                users.DELETE("/:id", deleteUser)
            }
            
            // 商品相关路由
            products := v1.Group("/products")
            {
                products.GET("", listProducts)
                products.POST("", createProduct)
                products.GET("/:id", getProduct)
                products.PUT("/:id", updateProduct)
                products.DELETE("/:id", deleteProduct)
            }
        }
        
        // API版本2
        v2 := r.Group("/api/v2")
        {
            // 新版本的用户路由
            users := v2.Group("/users")
            {
                users.GET("", listUsersV2)
                users.POST("", createUserV2)
            }
        }
        
        // 管理员路由组
        admin := r.Group("/admin")
        admin.Use(AuthMiddleware(), AdminMiddleware())
        {
            admin.GET("/dashboard", adminDashboard)
            admin.GET("/users", adminListUsers)
            admin.POST("/settings", updateSettings)
        }
        
        r.Run(":8080")
    }
    
    // 中间件：管理员权限检查
    func AdminMiddleware() gin.HandlerFunc {
        return func(c *gin.Context) {
            // 检查用户是否具有管理员权限
            if !isAdmin(c) {
                c.JSON(http.StatusForbidden, gin.H{"error": "需要管理员权限"})
                c.Abort()
                return
            }
            c.Next()
        }
    }
    ```

#### 进阶题
14. **如何在Gin中实现全局错误处理？**
    - 要求：提供一个全局错误处理的中间件代码，处理如404、500等错误。
    
    **答案：**
    全局错误处理可以通过中间件和自定义错误处理函数实现：

    ```go
    // 自定义错误结构
    type AppError struct {
        Code    int    `json:"code"`
        Message string `json:"message"`
        Err     error  `json:"-"`
    }
    
    // 错误处理中间件
    func ErrorHandler() gin.HandlerFunc {
        return func(c *gin.Context) {
            c.Next()
            
            // 检查是否有错误
            if len(c.Errors) > 0 {
                err := c.Errors.Last()
                switch e := err.Err.(type) {
                case *AppError:
                    c.JSON(e.Code, e)
                default:
                    c.JSON(http.StatusInternalServerError, gin.H{
                        "code":    500,
                        "message": "服务器内部错误",
                    })
                }
                c.Abort()
            }
        }
    }
    
    // 404处理
    func NoRouteHandler() gin.HandlerFunc {
        return func(c *gin.Context) {
            c.JSON(http.StatusNotFound, gin.H{
                "code":    404,
                "message": "请求的资源不存在",
            })
        }
    }
    
    // 使用示例
    func main() {
        r := gin.New()
        
        // 使用错误处理中间件
        r.Use(ErrorHandler())
        
        // 设置404处理
        r.NoRoute(NoRouteHandler())
        
        // 业务路由
        r.GET("/test", func(c *gin.Context) {
            // 抛出业务错误
            c.Error(&AppError{
                Code:    400,
                Message: "参数错误",
            })
        })
        
        r.Run(":8080")
    }
    ```

15. **Gin框架在高并发场景下的性能优化有哪些方法？**
    - 要求：讨论连接池、路由优化、JSON序列化等优化手段。
    
    **答案：**
    Gin框架在高并发场景下的优化方法：

    **1. 连接池优化**
    ```go
    // 数据库连接池配置
    func initDB() *sql.DB {
        db, err := sql.Open("mysql", "user:password@/dbname")
        if err != nil {
            log.Fatal(err)
        }
        
        // 设置连接池参数
        db.SetMaxOpenConns(100)                // 最大连接数
        db.SetMaxIdleConns(20)                 // 最大空闲连接数
        db.SetConnMaxLifetime(time.Hour)       // 连接最大生命周期
        db.SetConnMaxIdleTime(time.Minute * 5) // 空闲连接最大生命周期
        
        return db
    }
    ```

    **2. 路由优化**
    ```go
    // 1. 使用路由组减少路由匹配时间
    func setupRoutes(r *gin.Engine) {
        api := r.Group("/api")
        {
            api.GET("/users", handleUsers)
            api.GET("/products", handleProducts)
        }
    }
    
    // 2. 使用路由缓存
    func main() {
        gin.SetMode(gin.ReleaseMode) // 生产模式
        r := gin.Default()
        // ... 路由配置
    }
    ```

    **3. JSON序列化优化**
    ```go
    // 1. 使用结构体标签优化JSON序列化
    type User struct {
        ID        uint      `json:"id"`
        Name      string    `json:"name"`
        CreatedAt time.Time `json:"created_at"`
    }
    
    // 2. 使用缓冲池
    var bufferPool = sync.Pool{
        New: func() interface{} {
            return new(bytes.Buffer)
        },
    }
    
    func getBuffer() *bytes.Buffer {
        return bufferPool.Get().(*bytes.Buffer)
    }
    
    func putBuffer(buf *bytes.Buffer) {
        buf.Reset()
        bufferPool.Put(buf)
    }
    ```

    **4. 中间件优化**
    ```go
    // 1. 使用缓存中间件
    func CacheMiddleware(expiration time.Duration) gin.HandlerFunc {
        cache := cache.New(expiration, time.Minute)
        return func(c *gin.Context) {
            key := c.Request.URL.String()
            if data, found := cache.Get(key); found {
                c.JSON(200, data)
                c.Abort()
                return
            }
            c.Next()
        }
    }
    
    // 2. 使用限流中间件
    func RateLimitMiddleware(limit int) gin.HandlerFunc {
        limiter := rate.NewLimiter(rate.Limit(limit), limit)
        return func(c *gin.Context) {
            if !limiter.Allow() {
                c.JSON(429, gin.H{"error": "请求过于频繁"})
                c.Abort()
                return
            }
            c.Next()
        }
    }
    ```

16. **如何在Gin中实现基于JWT的认证？**
    - 要求：提供一个完整的JWT认证中间件代码，包括生成和验证token的逻辑。
    
    **答案：**
    下面是一个完整的JWT认证实现：

    ```go
    // JWT相关结构和方法
    type Claims struct {
        UserID   uint   `json:"user_id"`
        Username string `json:"username"`
        jwt.StandardClaims
    }
    
    // 生成JWT token
    func generateToken(userID uint, username string) (string, error) {
        claims := Claims{
            UserID:   userID,
            Username: username,
            StandardClaims: jwt.StandardClaims{
                ExpiresAt: time.Now().Add(24 * time.Hour).Unix(),
                IssuedAt:  time.Now().Unix(),
            },
        }
        
        token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
        return token.SignedString([]byte("your-secret-key"))
    }
    
    // JWT认证中间件
    func JWTAuthMiddleware() gin.HandlerFunc {
        return func(c *gin.Context) {
            authHeader := c.GetHeader("Authorization")
            if authHeader == "" {
                c.JSON(http.StatusUnauthorized, gin.H{"error": "未提供认证信息"})
                c.Abort()
                return
            }
            
            // 解析token
            tokenString := strings.Replace(authHeader, "Bearer ", "", 1)
            claims := &Claims{}
            
            token, err := jwt.ParseWithClaims(tokenString, claims, func(token *jwt.Token) (interface{}, error) {
                return []byte("your-secret-key"), nil
            })
            
            if err != nil || !token.Valid {
                c.JSON(http.StatusUnauthorized, gin.H{"error": "无效的token"})
                c.Abort()
                return
            }
            
            // 将用户信息存储到上下文
            c.Set("userID", claims.UserID)
            c.Set("username", claims.Username)
            
            c.Next()
        }
    }
    
    // 登录处理
    func login(c *gin.Context) {
        var loginForm struct {
            Username string `json:"username" binding:"required"`
            Password string `json:"password" binding:"required"`
        }
        
        if err := c.ShouldBindJSON(&loginForm); err != nil {
            c.JSON(http.StatusBadRequest, gin.H{"error": "无效的请求参数"})
            return
        }
        
        // 验证用户名和密码
        if !validateUser(loginForm.Username, loginForm.Password) {
            c.JSON(http.StatusUnauthorized, gin.H{"error": "用户名或密码错误"})
            return
        }
        
        // 生成token
        token, err := generateToken(1, loginForm.Username)
        if err != nil {
            c.JSON(http.StatusInternalServerError, gin.H{"error": "生成token失败"})
            return
        }
        
        c.JSON(http.StatusOK, gin.H{
            "token": token,
            "type":  "Bearer",
        })
    }
    
    // 使用示例
    func main() {
        r := gin.Default()
        
        // 公开路由
        r.POST("/login", login)
        
        // 需要认证的路由
        authorized := r.Group("/api")
        authorized.Use(JWTAuthMiddleware())
        {
            authorized.GET("/profile", func(c *gin.Context) {
                userID := c.GetUint("userID")
                username := c.GetString("username")
                c.JSON(200, gin.H{
                    "user_id":  userID,
                    "username": username,
                })
            })
        }
        
        r.Run(":8080")
    }
    ```

---

### 3. 数据库优化
#### 基础题
17. **数据库索引的作用是什么？如何选择合适的字段建立索引？**
    - 要求：解释B+树索引原理，说明索引选择的注意事项（如选择性、查询频率）。
    
    **答案：**
    数据库索引是提高查询效率的重要机制。

    **1. 索引的作用：**
    - 加快数据检索速度
    - 保证数据的唯一性
    - 加速表之间的连接
    - 减少排序和分组的时间

    **2. B+树索引原理：**
    - 所有数据都存储在叶子节点
    - 非叶子节点只存储索引值
    - 叶子节点通过链表相连
    - 支持范围查询和排序

    **3. 索引选择策略：**
    ```sql
    -- 1. 经常用于查询条件的字段
    CREATE INDEX idx_user_email ON users(email);
    
    -- 2. 经常用于排序的字段
    CREATE INDEX idx_order_created_at ON orders(created_at);
    
    -- 3. 经常用于连接的字段
    CREATE INDEX idx_order_user_id ON orders(user_id);
    
    -- 4. 选择性高的字段（区分度高的字段）
    CREATE INDEX idx_user_phone ON users(phone);
    ```

    **4. 索引使用注意事项：**
    ```go
    // 1. 避免在索引列上使用函数
    // 错误示例
    db.Where("DATE(created_at) = ?", date)
    
    // 正确示例
    db.Where("created_at >= ? AND created_at < ?", startDate, endDate)
    
    // 2. 避免使用不等于操作符
    // 错误示例
    db.Where("status != ?", "active")
    
    // 正确示例
    db.Where("status IN (?)", []string{"pending", "completed"})
    
    // 3. 避免使用OR条件
    // 错误示例
    db.Where("status = ? OR type = ?", "active", "premium")
    
    // 正确示例
    db.Where("status = ?", "active").Or("type = ?", "premium")
    ```

18. **事务的ACID特性是什么？如何在Go中实现数据库事务？**
    - 要求：提供使用database/sql包实现事务的代码示例。
    
    **答案：**
    事务的ACID特性：
    - Atomicity（原子性）：事务要么全部完成，要么全部不完成
    - Consistency（一致性）：事务执行前后，数据库状态保持一致
    - Isolation（隔离性）：并发事务之间互不影响
    - Durability（持久性）：事务完成后，修改永久保存

    **Go中实现事务：**
    ```go
    // 1. 基本事务操作
    func TransferMoney(db *sql.DB, fromID, toID int, amount float64) error {
        tx, err := db.Begin()
        if err != nil {
            return err
        }
        defer func() {
            if p := recover(); p != nil {
                tx.Rollback()
                panic(p)
            }
        }()
        
        // 扣除金额
        _, err = tx.Exec("UPDATE accounts SET balance = balance - ? WHERE id = ?", amount, fromID)
        if err != nil {
            tx.Rollback()
            return err
        }
        
        // 增加金额
        _, err = tx.Exec("UPDATE accounts SET balance = balance + ? WHERE id = ?", amount, toID)
        if err != nil {
            tx.Rollback()
            return err
        }
        
        return tx.Commit()
    }
    
    // 2. 使用事务隔离级别
    func TransferMoneyWithIsolation(db *sql.DB, fromID, toID int, amount float64) error {
        tx, err := db.BeginTx(context.Background(), &sql.TxOptions{
            Isolation: sql.LevelSerializable,
            ReadOnly:  false,
        })
        if err != nil {
            return err
        }
        defer tx.Rollback()
        
        // 检查余额
        var balance float64
        err = tx.QueryRow("SELECT balance FROM accounts WHERE id = ?", fromID).Scan(&balance)
        if err != nil {
            return err
        }
        
        if balance < amount {
            return errors.New("余额不足")
        }
        
        // 执行转账
        if err := TransferMoney(db, fromID, toID, amount); err != nil {
            return err
        }
        
        return tx.Commit()
    }
    
    // 3. 使用GORM实现事务
    func TransferMoneyWithGORM(db *gorm.DB, fromID, toID int, amount float64) error {
        return db.Transaction(func(tx *gorm.DB) error {
            var fromAccount, toAccount Account
            
            // 查询账户
            if err := tx.First(&fromAccount, fromID).Error; err != nil {
                return err
            }
            if err := tx.First(&toAccount, toID).Error; err != nil {
                return err
            }
            
            // 更新余额
            if err := tx.Model(&fromAccount).Update("balance", gorm.Expr("balance - ?", amount)).Error; err != nil {
                return err
            }
            if err := tx.Model(&toAccount).Update("balance", gorm.Expr("balance + ?", amount)).Error; err != nil {
                return err
            }
            
            return nil
        })
    }
    ```

19. **分库分表的适用场景是什么？有哪些常见的策略？**
    - 要求：说明分库分表的优缺点，介绍按范围、哈希分表的实现方式。
    
    **答案：**
    分库分表是解决数据库性能瓶颈的重要手段。

    **1. 适用场景：**
    - 单表数据量过大（超过千万级）
    - 并发访问量高
    - 数据增长速度快
    - 需要水平扩展

    **2. 分表策略：**
    ```go
    // 1. 按范围分表
    func getTableNameByRange(userID int64) string {
        tableIndex := userID / 1000000 // 每100万用户一个表
        return fmt.Sprintf("users_%d", tableIndex)
    }
    
    // 2. 按哈希分表
    func getTableNameByHash(userID int64) string {
        tableIndex := userID % 10 // 分成10个表
        return fmt.Sprintf("users_%d", tableIndex)
    }
    
    // 3. 按时间分表
    func getTableNameByTime(createdAt time.Time) string {
        return fmt.Sprintf("orders_%s", createdAt.Format("200601"))
    }
    ```

    **3. 分库分表实现示例：**
    ```go
    // 1. 使用中间件实现分库分表
    type ShardingDB struct {
        dbs map[string]*sql.DB
    }
    
    func (s *ShardingDB) GetDB(userID int64) *sql.DB {
        dbIndex := userID % int64(len(s.dbs))
        return s.dbs[fmt.Sprintf("db_%d", dbIndex)]
    }
    
    // 2. 使用GORM实现分表
    type User struct {
        ID        int64     `gorm:"primaryKey"`
        Name      string    `gorm:"column:name"`
        CreatedAt time.Time `gorm:"column:created_at"`
    }
    
    func (u *User) TableName() string {
        return getTableNameByHash(u.ID)
    }
    
    // 3. 分库分表查询示例
    func QueryUserByID(shardingDB *ShardingDB, userID int64) (*User, error) {
        db := shardingDB.GetDB(userID)
        tableName := getTableNameByHash(userID)
        
        var user User
        err := db.Table(tableName).Where("id = ?", userID).First(&user).Error
        if err != nil {
            return nil, err
        }
        return &user, nil
    }
    ```

#### 进阶题
20. **如何分析和优化慢查询？**
    - 要求：介绍慢查询日志、EXPLAIN分析工具，以及优化查询的具体方法（如改写SQL、添加索引）。
    
    **答案：**
    慢查询分析和优化是数据库性能调优的重要环节。

    **1. 慢查询日志配置：**
    ```sql
    -- 开启慢查询日志
    SET GLOBAL slow_query_log = 1;
    SET GLOBAL slow_query_log_file = '/var/log/mysql/slow.log';
    SET GLOBAL long_query_time = 2;  -- 设置慢查询阈值（秒）
    ```

    **2. EXPLAIN分析：**
    ```sql
    -- 分析查询执行计划
    EXPLAIN SELECT u.*, o.order_count 
    FROM users u 
    LEFT JOIN (
        SELECT user_id, COUNT(*) as order_count 
        FROM orders 
        GROUP BY user_id
    ) o ON u.id = o.user_id 
    WHERE u.status = 'active';
    ```

    **3. 查询优化示例：**
    ```go
    // 1. 优化JOIN查询
    // 优化前
    db.Raw(`
        SELECT u.*, o.order_count 
        FROM users u 
        LEFT JOIN (
            SELECT user_id, COUNT(*) as order_count 
            FROM orders 
            GROUP BY user_id
        ) o ON u.id = o.user_id 
        WHERE u.status = 'active'
    `)
    
    // 优化后
    db.Raw(`
        SELECT u.*, COUNT(o.id) as order_count 
        FROM users u 
        LEFT JOIN orders o ON u.id = o.user_id 
        WHERE u.status = 'active'
        GROUP BY u.id
    `)
    
    // 2. 优化IN查询
    // 优化前
    db.Where("id IN (?)", []int{1, 2, 3, 4, 5})
    
    // 优化后
    db.Where("id BETWEEN ? AND ?", 1, 5)
    
    // 3. 使用索引优化
    // 添加复合索引
    db.Exec("CREATE INDEX idx_user_status_created ON users(status, created_at)")
    ```

21. **在高并发场景下，如何避免数据库死锁？**
    - 要求：分析死锁发生的原因，提供避免死锁的策略（如固定访问顺序、短事务）。
    
    **答案：**
    死锁是并发事务中常见的问题，需要采取适当的策略避免。

    **1. 死锁预防：**
    ```go
    // 1. 固定访问顺序
    func TransferMoney(db *sql.DB, fromID, toID int, amount float64) error {
        // 确保总是先访问ID较小的记录
        if fromID > toID {
            fromID, toID = toID, fromID
            amount = -amount
        }
        
        tx, err := db.Begin()
        if err != nil {
            return err
        }
        defer tx.Rollback()
        
        // 按固定顺序更新记录
        _, err = tx.Exec("UPDATE accounts SET balance = balance - ? WHERE id = ?", amount, fromID)
        if err != nil {
            return err
        }
        
        _, err = tx.Exec("UPDATE accounts SET balance = balance + ? WHERE id = ?", amount, toID)
        if err != nil {
            return err
        }
        
        return tx.Commit()
    }
    
    // 2. 使用乐观锁
    func UpdateWithOptimisticLock(db *sql.DB, id int, newValue string) error {
        result, err := db.Exec(`
            UPDATE items 
            SET value = ?, version = version + 1 
            WHERE id = ? AND version = ?
        `, newValue, id, currentVersion)
        if err != nil {
            return err
        }
        
        rows, err := result.RowsAffected()
        if err != nil {
            return err
        }
        
        if rows == 0 {
            return errors.New("数据已被修改")
        }
        
        return nil
    }
    
    // 3. 使用事务超时
    func TransferWithTimeout(db *sql.DB, fromID, toID int, amount float64) error {
        ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
        defer cancel()
        
        tx, err := db.BeginTx(ctx, nil)
        if err != nil {
            return err
        }
        defer tx.Rollback()
        
        // 执行转账操作
        if err := TransferMoney(db, fromID, toID, amount); err != nil {
            return err
        }
        
        return tx.Commit()
    }
    ```

22. **分库分表后如何处理分布式事务？**
    - 要求：介绍分布式事务的挑战，说明使用如TCC或XA事务的解决方案。
    
    **答案：**
    分布式事务是分库分表后需要解决的重要问题。

    **1. TCC模式实现：**
    ```go
    // 1. 定义TCC接口
    type TCCService interface {
        Try(ctx context.Context, params interface{}) error
        Confirm(ctx context.Context, params interface{}) error
        Cancel(ctx context.Context, params interface{}) error
    }
    
    // 2. 转账服务实现
    type TransferService struct {
        db *sql.DB
    }
    
    func (s *TransferService) Try(ctx context.Context, params TransferParams) error {
        // 预扣款
        _, err := s.db.ExecContext(ctx, `
            UPDATE accounts 
            SET balance = balance - ?, 
                frozen_amount = frozen_amount + ? 
            WHERE id = ? AND balance >= ?
        `, params.Amount, params.Amount, params.FromID, params.Amount)
        return err
    }
    
    func (s *TransferService) Confirm(ctx context.Context, params TransferParams) error {
        // 确认转账
        _, err := s.db.ExecContext(ctx, `
            UPDATE accounts 
            SET frozen_amount = frozen_amount - ? 
            WHERE id = ?
        `, params.Amount, params.FromID)
        if err != nil {
            return err
        }
        
        _, err = s.db.ExecContext(ctx, `
            UPDATE accounts 
            SET balance = balance + ? 
            WHERE id = ?
        `, params.Amount, params.ToID)
        return err
    }
    
    func (s *TransferService) Cancel(ctx context.Context, params TransferParams) error {
        // 取消转账
        _, err := s.db.ExecContext(ctx, `
            UPDATE accounts 
            SET balance = balance + ?, 
                frozen_amount = frozen_amount - ? 
            WHERE id = ?
        `, params.Amount, params.Amount, params.FromID)
        return err
    }
    
    // 3. 事务协调器
    type TransactionCoordinator struct {
        services map[string]TCCService
    }
    
    func (c *TransactionCoordinator) Execute(ctx context.Context, params interface{}) error {
        // 1. Try阶段
        for _, service := range c.services {
            if err := service.Try(ctx, params); err != nil {
                // 执行Cancel
                c.Cancel(ctx, params)
                return err
            }
        }
        
        // 2. Confirm阶段
        for _, service := range c.services {
            if err := service.Confirm(ctx, params); err != nil {
                // 执行Cancel
                c.Cancel(ctx, params)
                return err
            }
        }
        
        return nil
    }
    
    func (c *TransactionCoordinator) Cancel(ctx context.Context, params interface{}) {
        for _, service := range c.services {
            service.Cancel(ctx, params)
        }
    }
    ```

    **2. 最终一致性实现：**
    ```go
    // 1. 消息表实现
    type Message struct {
        ID        int64     `gorm:"primaryKey"`
        Topic     string    `gorm:"column:topic"`
        Content   string    `gorm:"column:content"`
        Status    int       `gorm:"column:status"`
        CreatedAt time.Time `gorm:"column:created_at"`
    }
    
    // 2. 可靠消息服务
    type ReliableMessageService struct {
        db *sql.DB
        mq MessageQueue
    }
    
    func (s *ReliableMessageService) SendMessage(ctx context.Context, msg *Message) error {
        // 1. 保存消息
        tx, err := s.db.BeginTx(ctx, nil)
        if err != nil {
            return err
        }
        defer tx.Rollback()
        
        if err := s.saveMessage(tx, msg); err != nil {
            return err
        }
        
        // 2. 发送消息
        if err := s.mq.Send(msg); err != nil {
            return err
        }
        
        // 3. 更新消息状态
        if err := s.updateMessageStatus(tx, msg.ID, 1); err != nil {
            return err
        }
        
        return tx.Commit()
    }
    
    // 3. 消息补偿机制
    func (s *ReliableMessageService) Compensate() {
        ticker := time.NewTicker(time.Minute)
        for range ticker.C {
            // 查询未确认的消息
            messages, err := s.queryUnconfirmedMessages()
            if err != nil {
                continue
            }
            
            // 重试发送
            for _, msg := range messages {
                if err := s.mq.Send(msg); err != nil {
                    continue
                }
                s.updateMessageStatus(nil, msg.ID, 1)
            }
        }
    }
    ```

---

### 4. Redis应用
#### 基础题
23. **Redis的常见数据结构有哪些？各适用于哪些场景？**
    - 要求：列举String、Hash、List、Set、ZSet，并说明典型应用场景（如排行榜、计数器）。
    
    **答案：**
    Redis提供了丰富的数据结构，每种结构都有其特定的应用场景。

    **1. String（字符串）**
    ```go
    // 1. 计数器
    func IncrementCounter(rdb *redis.Client, key string) (int64, error) {
        return rdb.Incr(context.Background(), key).Result()
    }
    
    // 2. 缓存
    func SetCache(rdb *redis.Client, key string, value interface{}, expiration time.Duration) error {
        return rdb.Set(context.Background(), key, value, expiration).Err()
    }
    
    // 3. 分布式锁
    func AcquireLock(rdb *redis.Client, lockKey string, value string, expiration time.Duration) bool {
        return rdb.SetNX(context.Background(), lockKey, value, expiration).Val()
    }
    ```

    **2. Hash（哈希表）**
    ```go
    // 1. 用户信息存储
    func StoreUserInfo(rdb *redis.Client, userID string, userInfo map[string]interface{}) error {
        return rdb.HMSet(context.Background(), "user:"+userID, userInfo).Err()
    }
    
    // 2. 购物车
    func AddToCart(rdb *redis.Client, userID string, productID string, quantity int) error {
        return rdb.HIncrBy(context.Background(), "cart:"+userID, productID, int64(quantity)).Err()
    }
    ```

    **3. List（列表）**
    ```go
    // 1. 消息队列
    func PushMessage(rdb *redis.Client, queueName string, message string) error {
        return rdb.LPush(context.Background(), queueName, message).Err()
    }
    
    func PopMessage(rdb *redis.Client, queueName string) (string, error) {
        return rdb.BRPop(context.Background(), 0, queueName).Result()
    }
    
    // 2. 最新动态
    func AddLatestActivity(rdb *redis.Client, userID string, activity string) error {
        pipe := rdb.Pipeline()
        pipe.LPush(context.Background(), "activity:"+userID, activity)
        pipe.LTrim(context.Background(), "activity:"+userID, 0, 99) // 只保留最新的100条
        _, err := pipe.Exec(context.Background())
        return err
    }
    ```

    **4. Set（集合）**
    ```go
    // 1. 用户标签
    func AddUserTag(rdb *redis.Client, userID string, tag string) error {
        return rdb.SAdd(context.Background(), "tags:"+userID, tag).Err()
    }
    
    // 2. 共同关注
    func GetCommonFollowers(rdb *redis.Client, user1ID, user2ID string) ([]string, error) {
        return rdb.SInter(context.Background(), 
            "followers:"+user1ID, 
            "followers:"+user2ID,
        ).Result()
    }
    ```

    **5. ZSet（有序集合）**
    ```go
    // 1. 排行榜
    func UpdateLeaderboard(rdb *redis.Client, userID string, score float64) error {
        return rdb.ZAdd(context.Background(), "leaderboard", &redis.Z{
            Score:  score,
            Member: userID,
        }).Err()
    }
    
    func GetTopUsers(rdb *redis.Client, count int64) ([]string, error) {
        return rdb.ZRevRange(context.Background(), "leaderboard", 0, count-1).Result()
    }
    
    // 2. 延时队列
    func AddDelayedTask(rdb *redis.Client, taskID string, executeTime int64) error {
        return rdb.ZAdd(context.Background(), "delayed_tasks", &redis.Z{
            Score:  float64(executeTime),
            Member: taskID,
        }).Err()
    }
    ```

24. **如何使用Redis实现分布式锁？**
    - 要求：提供基于SETNX的分布式锁代码，说明锁的释放和超时机制。
    
    **答案：**
    分布式锁是分布式系统中常用的同步机制，Redis提供了很好的实现方式。

    **1. 基本实现：**
    ```go
    // 1. 简单的分布式锁
    type RedisLock struct {
        rdb    *redis.Client
        key    string
        value  string
        expire time.Duration
    }
    
    func NewRedisLock(rdb *redis.Client, key string, expire time.Duration) *RedisLock {
        return &RedisLock{
            rdb:    rdb,
            key:    key,
            value:  uuid.New().String(), // 使用UUID作为锁的值
            expire: expire,
        }
    }
    
    func (l *RedisLock) Lock() (bool, error) {
        return l.rdb.SetNX(context.Background(), l.key, l.value, l.expire).Result()
    }
    
    func (l *RedisLock) Unlock() error {
        // 使用Lua脚本保证原子性
        script := `
            if redis.call("get", KEYS[1]) == ARGV[1] then
                return redis.call("del", KEYS[1])
            else
                return 0
            end
        `
        return l.rdb.Eval(context.Background(), script, []string{l.key}, l.value).Err()
    }
    ```

    **2. 带重试的分布式锁：**
    ```go
    // 2. 带重试机制的分布式锁
    func (l *RedisLock) LockWithRetry(retryTimes int, retryDelay time.Duration) (bool, error) {
        for i := 0; i < retryTimes; i++ {
            locked, err := l.Lock()
            if err != nil {
                return false, err
            }
            if locked {
                return true, nil
            }
            time.Sleep(retryDelay)
        }
        return false, nil
    }
    ```

    **3. 自动续期的分布式锁：**
    ```go
    // 3. 自动续期的分布式锁
    type AutoRenewLock struct {
        *RedisLock
        stopChan chan struct{}
    }
    
    func NewAutoRenewLock(rdb *redis.Client, key string, expire time.Duration) *AutoRenewLock {
        return &AutoRenewLock{
            RedisLock: NewRedisLock(rdb, key, expire),
            stopChan:  make(chan struct{}),
        }
    }
    
    func (l *AutoRenewLock) Lock() (bool, error) {
        locked, err := l.RedisLock.Lock()
        if err != nil || !locked {
            return locked, err
        }
        
        // 启动自动续期
        go l.autoRenew()
        return true, nil
    }
    
    func (l *AutoRenewLock) autoRenew() {
        ticker := time.NewTicker(l.expire / 3)
        defer ticker.Stop()
        
        for {
            select {
            case <-ticker.C:
                // 续期
                l.rdb.Expire(context.Background(), l.key, l.expire)
            case <-l.stopChan:
                return
            }
        }
    }
    
    func (l *AutoRenewLock) Unlock() error {
        close(l.stopChan) // 停止自动续期
        return l.RedisLock.Unlock()
    }
    ```

25. **Redis缓存的穿透、击穿和雪崩是什么？如何解决？**
    - 要求：解释三种问题的原因，提供布隆过滤器、热点缓存、随机过期时间等解决方案。
    
    **答案：**
    缓存问题是分布式系统中常见的问题，需要采取不同的策略来解决。

    **1. 缓存穿透：**
    ```go
    // 1. 使用布隆过滤器
    type BloomFilter struct {
        rdb    *redis.Client
        key    string
        size   uint
        hashes uint
    }
    
    func NewBloomFilter(rdb *redis.Client, key string, size, hashes uint) *BloomFilter {
        return &BloomFilter{
            rdb:    rdb,
            key:    key,
            size:   size,
            hashes: hashes,
        }
    }
    
    func (bf *BloomFilter) Add(item string) error {
        for i := uint(0); i < bf.hashes; i++ {
            hash := bf.hash(item, i)
            err := bf.rdb.SetBit(context.Background(), bf.key, int64(hash), 1).Err()
            if err != nil {
                return err
            }
        }
        return nil
    }
    
    func (bf *BloomFilter) Exists(item string) (bool, error) {
        for i := uint(0); i < bf.hashes; i++ {
            hash := bf.hash(item, i)
            exists, err := bf.rdb.GetBit(context.Background(), bf.key, int64(hash)).Result()
            if err != nil {
                return false, err
            }
            if exists == 0 {
                return false, nil
            }
        }
        return true, nil
    }
    ```

    **2. 缓存击穿：**
    ```go
    // 2. 使用互斥锁防止缓存击穿
    type CacheWithMutex struct {
        rdb    *redis.Client
        mutex  sync.Mutex
        key    string
        getter func() (interface{}, error)
    }
    
    func (c *CacheWithMutex) Get() (interface{}, error) {
        // 1. 尝试从缓存获取
        val, err := c.rdb.Get(context.Background(), c.key).Result()
        if err == nil {
            return val, nil
        }
        
        // 2. 缓存未命中，使用互斥锁
        c.mutex.Lock()
        defer c.mutex.Unlock()
        
        // 3. 双重检查
        val, err = c.rdb.Get(context.Background(), c.key).Result()
        if err == nil {
            return val, nil
        }
        
        // 4. 从数据源获取
        newVal, err := c.getter()
        if err != nil {
            return nil, err
        }
        
        // 5. 更新缓存
        err = c.rdb.Set(context.Background(), c.key, newVal, time.Hour).Err()
        if err != nil {
            return nil, err
        }
        
        return newVal, nil
    }
    ```

    **3. 缓存雪崩：**
    ```go
    // 3. 使用随机过期时间防止缓存雪崩
    type CacheWithRandomExpire struct {
        rdb    *redis.Client
        key    string
        getter func() (interface{}, error)
    }
    
    func (c *CacheWithRandomExpire) Get() (interface{}, error) {
        // 1. 尝试从缓存获取
        val, err := c.rdb.Get(context.Background(), c.key).Result()
        if err == nil {
            return val, nil
        }
        
        // 2. 从数据源获取
        newVal, err := c.getter()
        if err != nil {
            return nil, err
        }
        
        // 3. 设置随机过期时间
        expire := time.Hour + time.Duration(rand.Intn(300))*time.Second
        err = c.rdb.Set(context.Background(), c.key, newVal, expire).Err()
        if err != nil {
            return nil, err
        }
        
        return newVal, nil
    }
    ```

#### 进阶题
26. **如何设计一个高效的Redis缓存策略？**
    - 要求：讨论缓存更新策略（如Cache-Aside、Write-Through），并说明如何避免缓存与数据库不一致。
    
    **答案：**
    高效的缓存策略需要考虑多个方面，包括更新策略、一致性保证等。

    **1. Cache-Aside模式：**
    ```go
    // 1. 读操作
    func (c *Cache) Get(key string) (interface{}, error) {
        // 1. 尝试从缓存获取
        val, err := c.rdb.Get(context.Background(), key).Result()
        if err == nil {
            return val, nil
        }
        
        // 2. 缓存未命中，从数据库获取
        val, err = c.db.Get(key)
        if err != nil {
            return nil, err
        }
        
        // 3. 更新缓存
        err = c.rdb.Set(context.Background(), key, val, c.expire).Err()
        if err != nil {
            return nil, err
        }
        
        return val, nil
    }
    
    // 2. 写操作
    func (c *Cache) Update(key string, value interface{}) error {
        // 1. 更新数据库
        err := c.db.Update(key, value)
        if err != nil {
            return err
        }
        
        // 2. 删除缓存
        return c.rdb.Del(context.Background(), key).Err()
    }
    ```

    **2. Write-Through模式：**
    ```go
    // 1. 写操作
    func (c *Cache) WriteThrough(key string, value interface{}) error {
        // 1. 更新数据库
        err := c.db.Update(key, value)
        if err != nil {
            return err
        }
        
        // 2. 更新缓存
        return c.rdb.Set(context.Background(), key, value, c.expire).Err()
    }
    
    // 2. 批量更新
    func (c *Cache) BatchWriteThrough(items map[string]interface{}) error {
        // 1. 更新数据库
        err := c.db.BatchUpdate(items)
        if err != nil {
            return err
        }
        
        // 2. 使用Pipeline批量更新缓存
        pipe := c.rdb.Pipeline()
        for key, value := range items {
            pipe.Set(context.Background(), key, value, c.expire)
        }
        _, err = pipe.Exec(context.Background())
        return err
    }
    ```

    **3. 缓存一致性保证：**
    ```go
    // 1. 使用版本号
    type VersionedCache struct {
        rdb    *redis.Client
        db     *sql.DB
        expire time.Duration
    }
    
    func (c *VersionedCache) Get(key string) (interface{}, error) {
        // 1. 获取缓存值和版本号
        val, err := c.rdb.HGetAll(context.Background(), key).Result()
        if err != nil {
            return nil, err
        }
        
        // 2. 检查版本号
        dbVersion, err := c.getDBVersion(key)
        if err != nil {
            return nil, err
        }
        
        if val["version"] != dbVersion {
            // 版本不一致，重新加载
            return c.reload(key)
        }
        
        return val["data"], nil
    }
    
    // 2. 使用消息队列保证最终一致性
    type ConsistentCache struct {
        rdb    *redis.Client
        db     *sql.DB
        mq     MessageQueue
    }
    
    func (c *ConsistentCache) Update(key string, value interface{}) error {
        // 1. 更新数据库
        err := c.db.Update(key, value)
        if err != nil {
            return err
        }
        
        // 2. 发送缓存更新消息
        return c.mq.Publish("cache_update", map[string]interface{}{
            "key":   key,
            "value": value,
        })
    }
    ```
    ---
27. **Redis在高并发场景下的性能瓶颈有哪些？如何优化？**
    - 要求：分析Redis单线程模型的限制，介绍持久化优化、Pipeline、集群等方法。
    
    **答案：**
    Redis在高并发场景下可能遇到多种性能瓶颈，需要采取相应的优化策略。

    **1. 使用Pipeline减少网络往返：**
    ```go
    // 1. 批量操作
    func BatchGet(rdb *redis.Client, keys []string) ([]interface{}, error) {
        pipe := rdb.Pipeline()
        cmds := make([]*redis.StringCmd, len(keys))
        
        // 1. 将命令加入Pipeline
        for i, key := range keys {
            cmds[i] = pipe.Get(context.Background(), key)
        }
        
        // 2. 执行Pipeline
        _, err := pipe.Exec(context.Background())
        if err != nil && err != redis.Nil {
            return nil, err
        }
        
        // 3. 获取结果
        results := make([]interface{}, len(keys))
        for i, cmd := range cmds {
            results[i], _ = cmd.Result()
        }
        
        return results, nil
    }
    
    // 2. 批量写入
    func BatchSet(rdb *redis.Client, items map[string]interface{}) error {
        pipe := rdb.Pipeline()
        
        for key, value := range items {
            pipe.Set(context.Background(), key, value, time.Hour)
        }
        
        _, err := pipe.Exec(context.Background())
        return err
    }
    ```

    **2. 使用Lua脚本保证原子性：**
    ```go
    // 1. 原子性计数器
    const incrementScript = `
        local current = redis.call('get', KEYS[1])
        if not current then
            redis.call('set', KEYS[1], ARGV[1])
            return ARGV[1]
        end
        local new = current + ARGV[1]
        redis.call('set', KEYS[1], new)
        return new
    `
    
    func AtomicIncrement(rdb *redis.Client, key string, increment int64) (int64, error) {
        result, err := rdb.Eval(context.Background(), incrementScript, []string{key}, increment).Result()
        if err != nil {
            return 0, err
        }
        return result.(int64), nil
    }
    
    // 2. 原子性限流器
    const rateLimitScript = `
        local key = KEYS[1]
        local limit = tonumber(ARGV[1])
        local current = tonumber(redis.call('get', key) or "0")
        if current + 1 > limit then
            return 0
        end
        redis.call('incrby', key, 1)
        redis.call('expire', key, ARGV[2])
        return 1
    `
    
    func RateLimit(rdb *redis.Client, key string, limit int64, window time.Duration) (bool, error) {
        result, err := rdb.Eval(context.Background(), rateLimitScript, 
            []string{key}, limit, window.Seconds()).Result()
        if err != nil {
            return false, err
        }
        return result.(int64) == 1, nil
    }
    ```

    **3. 使用ZSet实现滑动窗口限流：**
    ```go
    // 滑动窗口限流器
    func SlidingWindowRateLimit(rdb *redis.Client, key string, limit int64, window time.Duration) (bool, error) {
        now := time.Now().Unix()
        windowStart := now - int64(window.Seconds())
        
        // 1. 清理过期的请求记录
        rdb.ZRemRangeByScore(context.Background(), key, "0", strconv.FormatInt(windowStart, 10))
        
        // 2. 获取当前窗口内的请求数
        count, err := rdb.ZCard(context.Background(), key).Result()
        if err != nil {
            return false, err
        }
        
        // 3. 判断是否超过限制
        if count >= limit {
            return false, nil
        }
        
        // 4. 添加新的请求记录
        err = rdb.ZAdd(context.Background(), key, &redis.Z{
            Score:  float64(now),
            Member: now,
        }).Err()
        
        return err == nil, err
    }
    ```

    **4. 使用令牌桶算法实现限流：**
    ```go
    // 令牌桶限流器
    type TokenBucket struct {
        rdb        *redis.Client
        key        string
        capacity   int64
        rate       float64
        lastRefill time.Time
    }
    
    func NewTokenBucket(rdb *redis.Client, key string, capacity int64, rate float64) *TokenBucket {
        return &TokenBucket{
            rdb:        rdb,
            key:        key,
            capacity:   capacity,
            rate:       rate,
            lastRefill: time.Now(),
        }
    }
    
    func (tb *TokenBucket) Allow() (bool, error) {
        now := time.Now()
        elapsed := now.Sub(tb.lastRefill).Seconds()
        
        // 1. 计算需要补充的令牌数
        tokensToAdd := int64(elapsed * tb.rate)
        if tokensToAdd > 0 {
            // 2. 补充令牌
            current, err := tb.rdb.Get(context.Background(), tb.key).Int64()
            if err != nil && err != redis.Nil {
                return false, err
            }
            
            newTokens := current + tokensToAdd
            if newTokens > tb.capacity {
                newTokens = tb.capacity
            }
            
            err = tb.rdb.Set(context.Background(), tb.key, newTokens, 0).Err()
            if err != nil {
                return false, err
            }
            
            tb.lastRefill = now
        }
        
        // 3. 尝试获取令牌
        result, err := tb.rdb.Decr(context.Background(), tb.key).Result()
        if err != nil {
            return false, err
        }
        
        return result >= 0, nil
    }
    ```

    **5. 使用Redis Cluster进行水平扩展：**
    ```go
    // Redis Cluster配置示例
    func NewRedisCluster() *redis.ClusterClient {
        return redis.NewClusterClient(&redis.ClusterOptions{
            Addrs: []string{
                "redis-1:6379",
                "redis-2:6379",
                "redis-3:6379",
            },
            PoolSize:     10,
            MinIdleConns: 5,
            MaxRetries:   3,
        })
    }
    ```

    **6. 持久化优化：**
    ```go
    // 1. 使用RDB持久化
    func ConfigureRDB(rdb *redis.Client) error {
        return rdb.ConfigSet(context.Background(), "save", "900 1 300 10 60 10000").Err()
    }
    
    // 2. 使用AOF持久化
    func ConfigureAOF(rdb *redis.Client) error {
        return rdb.ConfigSet(context.Background(), "appendonly", "yes").Err()
    }
    ```

这些优化策略可以帮助Redis在高并发场景下提供更好的性能：
1. Pipeline减少网络往返次数
2. Lua脚本保证原子性操作
3. 滑动窗口和令牌桶算法实现精确的限流
4. Redis Cluster提供水平扩展能力
5. 合理的持久化配置平衡性能和可靠性

28. **如何使用Redis实现一个简单的限流器？**
    - 要求：提供基于ZSet或令牌桶算法的限流代码。

    **答案：**
    使用Redis实现限流器有多种方案，以下是两种常用的实现方式：

    1. **基于ZSet的滑动窗口限流：**
    ```go
    // 滑动窗口限流器
    type SlidingWindowLimiter struct {
        rdb    *redis.Client
        key    string
        limit  int64
        window time.Duration
    }
    
    func NewSlidingWindowLimiter(rdb *redis.Client, key string, limit int64, window time.Duration) *SlidingWindowLimiter {
        return &SlidingWindowLimiter{
            rdb:    rdb,
            key:    key,
            limit:  limit,
            window: window,
        }
    }
    
    func (l *SlidingWindowLimiter) Allow() (bool, error) {
        now := time.Now().Unix()
        windowStart := now - int64(l.window.Seconds())
        
        // 1. 清理过期的请求记录
        err := l.rdb.ZRemRangeByScore(context.Background(), l.key, "0", strconv.FormatInt(windowStart, 10)).Err()
        if err != nil {
            return false, err
        }
        
        // 2. 获取当前窗口内的请求数
        count, err := l.rdb.ZCard(context.Background(), l.key).Result()
        if err != nil {
            return false, err
        }
        
        // 3. 判断是否超过限制
        if count >= l.limit {
            return false, nil
        }
        
        // 4. 添加新的请求记录
        err = l.rdb.ZAdd(context.Background(), l.key, &redis.Z{
            Score:  float64(now),
            Member: now,
        }).Err()
        
        return err == nil, err
    }
    ```

    2. **基于令牌桶算法的限流：**
    ```go
    // 令牌桶限流器
    type TokenBucketLimiter struct {
        rdb        *redis.Client
        key        string
        capacity   int64
        rate       float64
        lastRefill time.Time
    }
    
    func NewTokenBucketLimiter(rdb *redis.Client, key string, capacity int64, rate float64) *TokenBucketLimiter {
        return &TokenBucketLimiter{
            rdb:        rdb,
            key:        key,
            capacity:   capacity,
            rate:       rate,
            lastRefill: time.Now(),
        }
    }
    
    func (l *TokenBucketLimiter) Allow() (bool, error) {
        now := time.Now()
        elapsed := now.Sub(l.lastRefill).Seconds()
        
        // 1. 计算需要补充的令牌数
        tokensToAdd := int64(elapsed * l.rate)
        if tokensToAdd > 0 {
            // 2. 补充令牌
            current, err := l.rdb.Get(context.Background(), l.key).Int64()
            if err != nil && err != redis.Nil {
                return false, err
            }
            
            newTokens := current + tokensToAdd
            if newTokens > l.capacity {
                newTokens = l.capacity
            }
            
            err = l.rdb.Set(context.Background(), l.key, newTokens, 0).Err()
            if err != nil {
                return false, err
            }
            
            l.lastRefill = now
        }
        
        // 3. 尝试获取令牌
        result, err := l.rdb.Decr(context.Background(), l.key).Result()
        if err != nil {
            return false, err
        }
        
        return result >= 0, nil
    }
    ```

    3. **使用示例：**
    ```go
    func main() {
        rdb := redis.NewClient(&redis.Options{
            Addr: "localhost:6379",
        })
    
        // 1. 创建滑动窗口限流器
        slidingLimiter := NewSlidingWindowLimiter(rdb, "sliding_window", 100, time.Minute)
        
        // 2. 创建令牌桶限流器
        tokenLimiter := NewTokenBucketLimiter(rdb, "token_bucket", 100, 10) // 每秒10个令牌
    
        // 3. 使用限流器
        for i := 0; i < 200; i++ {
            allowed, err := slidingLimiter.Allow()
            if err != nil {
                log.Printf("滑动窗口限流错误: %v", err)
                continue
            }
            
            if !allowed {
                log.Printf("请求被滑动窗口限流器拒绝")
                continue
            }
            
            allowed, err = tokenLimiter.Allow()
            if err != nil {
                log.Printf("令牌桶限流错误: %v", err)
                continue
            }
            
            if !allowed {
                log.Printf("请求被令牌桶限流器拒绝")
                continue
            }
            
            // 处理请求
            log.Printf("处理请求 %d", i)
        }
    }
    ```

    两种限流方案的特点：

    1. **滑动窗口限流**：
       - 优点：精确控制时间窗口内的请求数
       - 适用场景：需要严格控制单位时间内请求数的场景
       - 实现复杂度：中等

    2. **令牌桶限流**：
       - 优点：支持突发流量，平滑限流
       - 适用场景：需要允许一定突发流量的场景
       - 实现复杂度：较高

    选择建议：
    - 如果需要严格控制请求频率，选择滑动窗口限流
    - 如果需要允许突发流量，选择令牌桶限流
    - 如果系统对性能要求较高，建议使用令牌桶限流

29. **RabbitMQ的核心组件有哪些？如何工作？**
    - 要求：解释Exchange、Queue、Binding的概念及消息流转过程。
    
    **答案：**
    RabbitMQ的核心组件包括：

    1. **Exchange（交换机）**：
    - Direct Exchange：完全匹配routing key
    - Topic Exchange：支持通配符匹配
    - Fanout Exchange：广播模式
    - Headers Exchange：基于消息属性匹配

    2. **Queue（队列）**：
    - 存储消息的容器
    - 支持持久化
    - 支持消息优先级

    3. **Binding（绑定）**：
    - 定义Exchange和Queue之间的关系
    - 指定routing key或binding key

    **示例代码：**
    ```go
    // 1. 创建连接
    func NewRabbitMQConnection() (*amqp.Connection, error) {
        return amqp.Dial("amqp://guest:guest@localhost:5672/")
    }
    
    // 2. 声明Exchange
    func DeclareExchange(ch *amqp.Channel) error {
        return ch.ExchangeDeclare(
            "my_exchange",   // 交换机名称
            "direct",        // 交换机类型
            true,           // 持久化
            false,          // 自动删除
            false,          // 内部使用
            false,          // 不等待
            nil,            // 参数
        )
    }
    
    // 3. 声明Queue
    func DeclareQueue(ch *amqp.Channel) (amqp.Queue, error) {
        return ch.QueueDeclare(
            "my_queue",     // 队列名称
            true,          // 持久化
            false,         // 自动删除
            false,         // 独占
            false,         // 不等待
            nil,           // 参数
        )
    }
    
    // 4. 创建Binding
    func CreateBinding(ch *amqp.Channel, queue, exchange, key string) error {
        return ch.QueueBind(
            queue,          // 队列名称
            key,           // routing key
            exchange,      // 交换机名称
            false,         // 不等待
            nil,           // 参数
        )
    }
    ```

30. **RabbitMQ的消费确认机制（ACK）如何使用？**
    - 要求：提供Go代码示例，展示手动确认和自动确认的实现。

    **答案：**
    RabbitMQ提供了两种确认机制：

    1. **自动确认**：
    ```go
    // 自动确认模式
    func AutoAckConsumer(ch *amqp.Channel, queue string) (<-chan amqp.Delivery, error) {
        return ch.Consume(
            queue,          // 队列名称
            "",            // 消费者标签
            true,          // 自动确认
            false,         // 独占
            false,         // 不等待
            false,         // 不阻塞
            nil,           // 参数
        )
    }
    ```

    2. **手动确认**：
    ```go
    // 手动确认模式
    func ManualAckConsumer(ch *amqp.Channel, queue string) (<-chan amqp.Delivery, error) {
        return ch.Consume(
            queue,          // 队列名称
            "",            // 消费者标签
            false,         // 手动确认
            false,         // 独占
            false,         // 不等待
            false,         // 不阻塞
            nil,           // 参数
        )
    }
    
    // 处理消息并确认
    func ProcessMessage(delivery amqp.Delivery) error {
        // 处理消息
        err := process(delivery.Body)
        if err != nil {
            // 处理失败，拒绝消息并重新入队
            return delivery.Reject(true)
        }
        
        // 处理成功，确认消息
        return delivery.Ack(false)
    }
    ```

31. **RabbitMQ的死信队列有什么用途？**
    - 要求：说明死信队列的配置和典型场景（如消息重试、失败处理）。

    **答案：**
    死信队列（DLX）用于处理无法被正常消费的消息，常见场景包括：

    1. **消息重试**：
    ```go
    // 配置死信队列
    func SetupDeadLetterQueue(ch *amqp.Channel) error {
        // 1. 声明死信交换机
        err := ch.ExchangeDeclare(
            "dlx_exchange",
            "direct",
            true,
            false,
            false,
            false,
            nil,
        )
        if err != nil {
            return err
        }
    
        // 2. 声明死信队列
        _, err = ch.QueueDeclare(
            "dlx_queue",
            true,
            false,
            false,
            false,
            nil,
        )
        if err != nil {
            return err
        }
    
        // 3. 绑定死信队列
        err = ch.QueueBind(
            "dlx_queue",
            "dlx_routing_key",
            "dlx_exchange",
            false,
            nil,
        )
        return err
    }
    
    // 配置主队列的死信属性
    func SetupMainQueueWithDLX(ch *amqp.Channel) error {
        args := amqp.Table{
            "x-dead-letter-exchange":    "dlx_exchange",
            "x-dead-letter-routing-key": "dlx_routing_key",
            "x-message-ttl":             int32(60000), // 消息TTL：60秒
        }
    
        _, err := ch.QueueDeclare(
            "main_queue",
            true,
            false,
            false,
            false,
            args,
        )
        return err
    }
    ```

    2. **失败处理**：
    ```go
    // 处理死信消息
    func ProcessDeadLetter(delivery amqp.Delivery) error {
        // 1. 检查重试次数
        retryCount := getRetryCount(delivery.Headers)
        if retryCount >= 3 {
            // 超过重试次数，记录到失败日志
            return logFailure(delivery)
        }
    
        // 2. 增加重试次数
        delivery.Headers["retry_count"] = retryCount + 1
    
        // 3. 重新发布消息
        return ch.Publish(
            "main_exchange",
            "main_routing_key",
            false,
            false,
            amqp.Publishing{
                Headers:      delivery.Headers,
                ContentType:  delivery.ContentType,
                Body:        delivery.Body,
            },
        )
    }
    ```

#### 进阶题
32. **如何保证RabbitMQ消息的可靠性投递？**
    - 要求：讨论生产者确认机制、消费者幂等性、消息持久化的实现。

    **答案：**
    保证RabbitMQ消息可靠性投递需要从多个层面进行设计：

    1. **生产者确认机制：**
    ```go
    // 1. 开启发布确认
    func EnablePublisherConfirms(ch *amqp.Channel) error {
        return ch.Confirm(false)
    }
    
    // 2. 发布消息并等待确认
    func PublishWithConfirm(ch *amqp.Channel, exchange, routingKey string, msg []byte) error {
        // 创建确认通道
        confirmChan := ch.NotifyPublish(make(chan amqp.Confirmation, 1))
        
        // 发布消息
        err := ch.Publish(
            exchange,
            routingKey,
            false,  // mandatory
            false,  // immediate
            amqp.Publishing{
                ContentType:  "text/plain",
                Body:        msg,
                DeliveryMode: amqp.Persistent, // 消息持久化
            },
        )
        if err != nil {
            return err
        }
    
        // 等待确认
        if confirmed := <-confirmChan; !confirmed.Ack {
            return fmt.Errorf("消息发布失败")
        }
        return nil
    }
    ```

    2. **消费者幂等性处理：**
    ```go
    // 1. 使用Redis实现幂等性检查
    type MessageProcessor struct {
        rdb *redis.Client
    }
    
    func (p *MessageProcessor) ProcessMessage(delivery amqp.Delivery) error {
        // 1. 生成消息唯一标识
        messageId := delivery.MessageId
        if messageId == "" {
            messageId = fmt.Sprintf("%s-%d", delivery.RoutingKey, time.Now().UnixNano())
        }
    
        // 2. 检查消息是否已处理
        exists, err := p.rdb.SetNX(context.Background(), 
            fmt.Sprintf("msg:%s", messageId), 
            "1", 
            24*time.Hour).Result()
        if err != nil {
            return err
        }
        if !exists {
            // 消息已处理，直接确认
            return delivery.Ack(false)
        }
    
        // 3. 处理消息
        err = p.doProcess(delivery.Body)
        if err != nil {
            // 处理失败，拒绝消息并重新入队
            return delivery.Reject(true)
        }
    
        // 4. 确认消息
        return delivery.Ack(false)
    }
    ```

    3. **消息持久化配置：**
    ```go
    // 1. 声明持久化队列
    func DeclareDurableQueue(ch *amqp.Channel) (amqp.Queue, error) {
        return ch.QueueDeclare(
            "durable_queue",
            true,  // durable
            false, // delete when unused
            false, // exclusive
            false, // no-wait
            nil,   // arguments
        )
    }
    
    // 2. 声明持久化交换机
    func DeclareDurableExchange(ch *amqp.Channel) error {
        return ch.ExchangeDeclare(
            "durable_exchange",
            "direct",
            true,  // durable
            false, // delete when unused
            false, // internal
            false, // no-wait
            nil,   // arguments
        )
    }
    ```

33. **在高并发场景下，RabbitMQ的性能瓶颈如何优化？**
    - 要求：介绍队列分片、延迟队列、消费者扩展等优化手段。

    **答案：**
    在高并发场景下，可以通过以下方式优化RabbitMQ性能：

    1. **队列分片：**
    ```go
    // 1. 创建分片队列
    func CreateShardedQueues(ch *amqp.Channel, baseName string, shardCount int) error {
        for i := 0; i < shardCount; i++ {
            queueName := fmt.Sprintf("%s_%d", baseName, i)
            _, err := ch.QueueDeclare(
                queueName,
                true,  // durable
                false, // delete when unused
                false, // exclusive
                false, // no-wait
                nil,   // arguments
            )
            if err != nil {
                return err
            }
        }
        return nil
    }
    
    // 2. 消息路由到分片队列
    func RouteToShard(ch *amqp.Channel, exchange, messageId string, body []byte) error {
        // 使用消息ID的哈希值选择分片
        shardIndex := hash(messageId) % shardCount
        routingKey := fmt.Sprintf("%s_%d", baseName, shardIndex)
        
        return ch.Publish(
            exchange,
            routingKey,
            false,
            false,
            amqp.Publishing{
                MessageId: messageId,
                Body:     body,
            },
        )
    }
    ```

    2. **延迟队列实现：**
    ```go
    // 1. 配置延迟队列
    func SetupDelayQueue(ch *amqp.Channel) error {
        // 声明延迟交换机
        err := ch.ExchangeDeclare(
            "delay_exchange",
            "direct",
            true,
            false,
            false,
            false,
            nil,
        )
        if err != nil {
            return err
        }
    
        // 声明延迟队列
        args := amqp.Table{
            "x-dead-letter-exchange":    "main_exchange",
            "x-dead-letter-routing-key": "main_queue",
            "x-message-ttl":             int32(60000), // 60秒延迟
        }
        
        _, err = ch.QueueDeclare(
            "delay_queue",
            true,
            false,
            false,
            false,
            args,
        )
        return err
    }
    
    // 2. 发送延迟消息
    func SendDelayedMessage(ch *amqp.Channel, body []byte, delay time.Duration) error {
        return ch.Publish(
            "delay_exchange",
            "delay_queue",
            false,
            false,
            amqp.Publishing{
                Body: body,
                Headers: amqp.Table{
                    "x-delay": int32(delay.Milliseconds()),
                },
            },
        )
    }
    ```

    3. **消费者扩展：**
    ```go
    // 1. 消费者池
    type ConsumerPool struct {
        ch        *amqp.Channel
        queue     string
        workers   int
        processor MessageProcessor
    }
    
    func (p *ConsumerPool) Start() error {
        for i := 0; i < p.workers; i++ {
            go p.worker(i)
        }
        return nil
    }
    
    func (p *ConsumerPool) worker(id int) {
        msgs, err := p.ch.Consume(
            p.queue,
            fmt.Sprintf("consumer_%d", id),
            false,
            false,
            false,
            false,
            nil,
        )
        if err != nil {
            log.Printf("消费者 %d 启动失败: %v", id, err)
            return
        }
    
        for msg := range msgs {
            err := p.processor.ProcessMessage(msg)
            if err != nil {
                log.Printf("消费者 %d 处理消息失败: %v", id, err)
            }
        }
    }
    ```

34. **如何使用RabbitMQ实现一个延迟任务队列？**
    - 要求：提供基于TTL和死信队列的延迟队列实现代码。

    **答案：**
    实现延迟任务队列有两种主要方式：

    1. **基于TTL和死信队列：**
    ```go
    // 1. 配置延迟队列
    func SetupDelayQueue(ch *amqp.Channel) error {
        // 声明死信交换机
        err := ch.ExchangeDeclare(
            "dlx_exchange",
            "direct",
            true,
            false,
            false,
            false,
            nil,
        )
        if err != nil {
            return err
        }
    
        // 声明死信队列
        _, err = ch.QueueDeclare(
            "dlx_queue",
            true,
            false,
            false,
            false,
            nil,
        )
        if err != nil {
            return err
        }
    
        // 绑定死信队列
        err = ch.QueueBind(
            "dlx_queue",
            "dlx_routing_key",
            "dlx_exchange",
            false,
            nil,
        )
        if err != nil {
            return err
        }
    
        // 声明延迟队列
        args := amqp.Table{
            "x-dead-letter-exchange":    "dlx_exchange",
            "x-dead-letter-routing-key": "dlx_routing_key",
        }
    
        _, err = ch.QueueDeclare(
            "delay_queue",
            true,
            false,
            false,
            false,
            args,
        )
        return err
    }
    
    // 2. 发送延迟消息
    func SendDelayedMessage(ch *amqp.Channel, body []byte, delay time.Duration) error {
        return ch.Publish(
            "delay_queue",
            "",
            false,
            false,
            amqp.Publishing{
                Body: body,
                Headers: amqp.Table{
                    "x-delay": int32(delay.Milliseconds()),
                },
            },
        )
    }
    ```

    2. **基于延迟插件：**
    ```go
    // 1. 配置延迟交换机
    func SetupDelayExchange(ch *amqp.Channel) error {
        args := amqp.Table{
            "x-delayed-type": "direct",
        }
        
        return ch.ExchangeDeclare(
            "delayed_exchange",
            "x-delayed-message",
            true,
            false,
            false,
            false,
            args,
        )
    }
    
    // 2. 发送延迟消息
    func SendDelayedMessageWithPlugin(ch *amqp.Channel, body []byte, delay time.Duration) error {
        return ch.Publish(
            "delayed_exchange",
            "delayed_queue",
            false,
            false,
            amqp.Publishing{
                Body: body,
                Headers: amqp.Table{
                    "x-delay": int32(delay.Milliseconds()),
                },
            },
        )
    }
    ```

    两种实现方式的比较：
    1. **基于TTL和死信队列**：
       - 优点：不需要额外插件，兼容性好
       - 缺点：消息在延迟期间会占用队列空间
       - 适用场景：延迟时间较短，消息量不大的场景

    2. **基于延迟插件**：
       - 优点：性能更好，不占用队列空间
       - 缺点：需要安装额外插件
       - 适用场景：延迟时间较长，消息量大的场景

---

### 6. 微服务与分布式系统
#### 基础题
38. **微服务架构的优缺点是什么？与单体架构的区别？**
    - 要求：分析微服务的独立性、扩展性，以及带来的复杂性问题。

    **答案：**
    微服务架构与单体架构的主要区别和特点：

    1. **架构特点对比**：
    ```
    单体架构：
    - 所有功能模块打包在一起
    - 共享同一个数据库
    - 部署简单，维护成本低
    - 扩展性差，耦合度高

    微服务架构：
    - 服务独立部署和扩展
    - 每个服务可以使用不同的数据库
    - 部署复杂，维护成本高
    - 扩展性好，耦合度低
    ```

    2. **微服务架构的优点**：
    - 服务独立部署和扩展
    - 技术栈灵活
    - 故障隔离
    - 团队自治
    - 持续交付

    3. **微服务架构的缺点**：
    - 分布式系统复杂性
    - 服务间通信开销
    - 数据一致性挑战
    - 运维复杂度增加
    - 测试难度提高

39. **服务发现的原理是什么？有哪些常见的服务发现工具？**
    - 要求：介绍Consul、Eureka、etcd等工具的原理和使用场景。

    **答案：**
    服务发现是微服务架构中的关键组件，主要实现方式：

    1. **基于Consul的服务发现**：
    ```go
    // 1. 服务注册
    type ServiceRegistry struct {
        client *consul.Client
    }

    func (r *ServiceRegistry) Register(serviceID, serviceName, address string, port int) error {
        registration := &consul.AgentServiceRegistration{
            ID:      serviceID,
            Name:    serviceName,
            Address: address,
            Port:    port,
            Check: &consul.AgentServiceCheck{
                HTTP:     fmt.Sprintf("http://%s:%d/health", address, port),
                Interval: "10s",
                Timeout:  "5s",
            },
        }
        return r.client.Agent().ServiceRegister(registration)
    }

    // 2. 服务发现
    func (r *ServiceRegistry) Discover(serviceName string) ([]*consul.ServiceEntry, error) {
        entries, _, err := r.client.Health().Service(serviceName, "", true, nil)
        return entries, err
    }
    ```

    2. **基于etcd的服务发现**：
    ```go
    // 1. 服务注册
    type EtcdRegistry struct {
        client *clientv3.Client
    }

    func (r *EtcdRegistry) Register(serviceID, serviceName, address string, ttl int64) error {
        key := fmt.Sprintf("/services/%s/%s", serviceName, serviceID)
        value := address
        
        // 创建租约
        lease, err := r.client.Grant(context.Background(), ttl)
        if err != nil {
            return err
        }
        
        // 注册服务并绑定租约
        _, err = r.client.Put(context.Background(), key, value, clientv3.WithLease(lease.ID))
        if err != nil {
            return err
        }
        
        // 自动续租
        keepAliveCh, err := r.client.KeepAlive(context.Background(), lease.ID)
        if err != nil {
            return err
        }
        
        go func() {
            for {
                select {
                case _, ok := <-keepAliveCh:
                    if !ok {
                        return
                    }
                }
            }
        }()
        
        return nil
    }

    // 2. 服务发现
    func (r *EtcdRegistry) Discover(serviceName string) ([]string, error) {
        key := fmt.Sprintf("/services/%s", serviceName)
        resp, err := r.client.Get(context.Background(), key, clientv3.WithPrefix())
        if err != nil {
            return nil, err
        }
        
        var addresses []string
        for _, kv := range resp.Kvs {
            addresses = append(addresses, string(kv.Value))
        }
        return addresses, nil
    }
    ```

40. **负载均衡的常见策略有哪些？**
    - 要求：说明轮询、最少连接、加权轮询等策略的适用场景。

    **答案：**
    常见的负载均衡策略及其实现：

    1. **轮询策略**：
    ```go
    type RoundRobinLoadBalancer struct {
        servers []string
        current int
        mu      sync.Mutex
    }

    func (lb *RoundRobinLoadBalancer) Next() string {
        lb.mu.Lock()
        defer lb.mu.Unlock()
        
        server := lb.servers[lb.current]
        lb.current = (lb.current + 1) % len(lb.servers)
        return server
    }
    ```

    2. **最少连接策略**：
    ```go
    type LeastConnLoadBalancer struct {
        servers    []string
        connCounts map[string]int
        mu         sync.Mutex
    }

    func (lb *LeastConnLoadBalancer) Next() string {
        lb.mu.Lock()
        defer lb.mu.Unlock()
        
        var minConn = math.MaxInt32
        var selected string
        
        for _, server := range lb.servers {
            if count := lb.connCounts[server]; count < minConn {
                minConn = count
                selected = server
            }
        }
        
        lb.connCounts[selected]++
        return selected
    }

    func (lb *LeastConnLoadBalancer) Release(server string) {
        lb.mu.Lock()
        defer lb.mu.Unlock()
        
        if count := lb.connCounts[server]; count > 0 {
            lb.connCounts[server]--
        }
    }
    ```

    3. **加权轮询策略**：
    ```go
    type WeightedRoundRobinLoadBalancer struct {
        servers []struct {
            server string
            weight int
        }
        current int
        mu      sync.Mutex
    }

    func (lb *WeightedRoundRobinLoadBalancer) Next() string {
        lb.mu.Lock()
        defer lb.mu.Unlock()
        
        server := lb.servers[lb.current].server
        lb.current = (lb.current + 1) % len(lb.servers)
        return server
    }
    ```

    4. **一致性哈希策略**：
    ```go
    type ConsistentHashLoadBalancer struct {
        hash     *consistenthash.Consistent
        servers  []string
    }

    func (lb *ConsistentHashLoadBalancer) Next(key string) string {
        return lb.hash.Get(key)
    }
    ```

    各种策略的适用场景：
    1. **轮询策略**：
       - 适用场景：服务器性能相近
       - 优点：实现简单，负载均衡
       - 缺点：不考虑服务器实际负载

    2. **最少连接策略**：
       - 适用场景：服务器性能差异大
       - 优点：考虑服务器实际负载
       - 缺点：需要维护连接数统计

    3. **加权轮询策略**：
       - 适用场景：服务器性能差异大
       - 优点：可以按权重分配请求
       - 缺点：配置复杂

    4. **一致性哈希策略**：
       - 适用场景：需要会话保持
       - 优点：减少服务器变化的影响
       - 缺点：可能造成负载不均衡

#### 进阶题
41. **如何设计一个高可用的微服务系统？**
    - 要求：讨论熔断、限流、重试、超时控制等机制的实现。

    **答案：**
    设计高可用微服务系统需要从多个层面进行考虑：

    1. **熔断器实现**：
    ```go
    // 1. 熔断器状态
    type CircuitBreakerState int

    const (
        StateClosed CircuitBreakerState = iota
        StateHalfOpen
        StateOpen
    )

    // 2. 熔断器
    type CircuitBreaker struct {
        state          CircuitBreakerState
        failureCount   int
        threshold      int
        resetTimeout   time.Duration
        lastFailure    time.Time
        mu             sync.RWMutex
    }

    func (cb *CircuitBreaker) Execute(f func() error) error {
        if !cb.allowRequest() {
            return ErrCircuitOpen
        }

        err := f()
        cb.recordResult(err)
        return err
    }

    func (cb *CircuitBreaker) allowRequest() bool {
        cb.mu.RLock()
        defer cb.mu.RUnlock()

        switch cb.state {
        case StateClosed:
            return true
        case StateOpen:
            if time.Since(cb.lastFailure) > cb.resetTimeout {
                cb.mu.RUnlock()
                cb.mu.Lock()
                cb.state = StateHalfOpen
                cb.mu.Unlock()
                cb.mu.RLock()
                return true
            }
            return false
        case StateHalfOpen:
            return true
        default:
            return false
        }
    }

    func (cb *CircuitBreaker) recordResult(err error) {
        cb.mu.Lock()
        defer cb.mu.Unlock()

        if err != nil {
            cb.failureCount++
            if cb.failureCount >= cb.threshold {
                cb.state = StateOpen
                cb.lastFailure = time.Now()
            }
        } else {
            cb.failureCount = 0
            cb.state = StateClosed
        }
    }
    ```

    2. **限流器实现**：
    ```go
    // 1. 令牌桶限流器
    type TokenBucketLimiter struct {
        tokens         int64
        capacity       int64
        rate           int64
        lastRefillTime time.Time
        mu             sync.Mutex
    }

    func (tb *TokenBucketLimiter) Allow() bool {
        tb.mu.Lock()
        defer tb.mu.Unlock()

        now := time.Now()
        elapsed := now.Sub(tb.lastRefillTime)
        tokensToAdd := int64(elapsed.Seconds() * float64(tb.rate))

        if tokensToAdd > 0 {
            tb.tokens = min(tb.capacity, tb.tokens+tokensToAdd)
            tb.lastRefillTime = now
        }

        if tb.tokens > 0 {
            tb.tokens--
            return true
        }
        return false
    }
    ```

    3. **重试机制**：
    ```go
    // 1. 重试策略
    type RetryStrategy struct {
        maxRetries  int
        backoff     time.Duration
        maxBackoff  time.Duration
    }

    func (rs *RetryStrategy) Execute(f func() error) error {
        var err error
        for i := 0; i <= rs.maxRetries; i++ {
            err = f()
            if err == nil {
                return nil
            }

            if i < rs.maxRetries {
                backoff := rs.backoff * time.Duration(1<<uint(i))
                if backoff > rs.maxBackoff {
                    backoff = rs.maxBackoff
                }
                time.Sleep(backoff)
            }
        }
        return err
    }
    ```

    4. **超时控制**：
    ```go
    // 1. 带超时的HTTP客户端
    type TimeoutClient struct {
        client  *http.Client
        timeout time.Duration
    }

    func (tc *TimeoutClient) Do(req *http.Request) (*http.Response, error) {
        ctx, cancel := context.WithTimeout(req.Context(), tc.timeout)
        defer cancel()

        req = req.WithContext(ctx)
        return tc.client.Do(req)
    }

    // 2. 服务调用超时控制
    func (s *Service) CallWithTimeout(ctx context.Context, req *Request) (*Response, error) {
        ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
        defer cancel()

        ch := make(chan *Response, 1)
        errCh := make(chan error, 1)

        go func() {
            resp, err := s.processRequest(req)
            if err != nil {
                errCh <- err
                return
            }
            ch <- resp
        }()

        select {
        case resp := <-ch:
            return resp, nil
        case err := <-errCh:
            return nil, err
        case <-ctx.Done():
            return nil, ctx.Err()
        }
    }
    ```

42. **在微服务中如何处理分布式系统的数据一致性？**
    - 要求：介绍CAP理论，分析最终一致性和强一致性的实现方式（如Saga模式、2PC）。

    **答案：**
    分布式系统数据一致性处理方案：

    1. **Saga模式实现**：
    ```go
    // 1. Saga事务管理器
    type SagaManager struct {
        steps []SagaStep
    }

    type SagaStep struct {
        Name           string
        Execute        func() error
        Compensate     func() error
        IsCompensating bool
    }

    func (sm *SagaManager) Execute() error {
        for i, step := range sm.steps {
            if err := step.Execute(); err != nil {
                // 执行补偿
                return sm.compensate(i)
            }
        }
        return nil
    }

    func (sm *SagaManager) compensate(failedStep int) error {
        for i := failedStep; i >= 0; i-- {
            if err := sm.steps[i].Compensate(); err != nil {
                return err
            }
        }
        return nil
    }

    // 2. 使用示例
    func NewOrderSaga() *SagaManager {
        return &SagaManager{
            steps: []SagaStep{
                {
                    Name: "创建订单",
                    Execute: func() error {
                        return createOrder()
                    },
                    Compensate: func() error {
                        return deleteOrder()
                    },
                },
                {
                    Name: "扣减库存",
                    Execute: func() error {
                        return decreaseInventory()
                    },
                    Compensate: func() error {
                        return increaseInventory()
                    },
                },
            },
        }
    }
    ```

    2. **2PC（两阶段提交）实现**：
    ```go
    // 1. 事务协调者
    type Coordinator struct {
        participants []Participant
    }

    type Participant interface {
        Prepare() error
        Commit() error
        Rollback() error
    }

    func (c *Coordinator) Execute() error {
        // 第一阶段：准备
        for _, p := range c.participants {
            if err := p.Prepare(); err != nil {
                // 回滚所有参与者
                c.rollback()
                return err
            }
        }

        // 第二阶段：提交
        for _, p := range c.participants {
            if err := p.Commit(); err != nil {
                // 记录错误，但继续提交其他参与者
                log.Printf("提交失败: %v", err)
            }
        }
        return nil
    }

    func (c *Coordinator) rollback() {
        for _, p := range c.participants {
            if err := p.Rollback(); err != nil {
                log.Printf("回滚失败: %v", err)
            }
        }
    }
    ```

    3. **最终一致性实现**：
    ```go
    // 1. 消息队列实现最终一致性
    type EventPublisher struct {
        mq MessageQueue
    }

    func (p *EventPublisher) PublishEvent(event Event) error {
        // 1. 保存事件到本地数据库
        if err := p.saveEvent(event); err != nil {
            return err
        }

        // 2. 发送事件到消息队列
        return p.mq.Publish(event)
    }

    // 2. 事件处理器
    type EventHandler struct {
        db Database
    }

    func (h *EventHandler) HandleEvent(event Event) error {
        // 1. 检查事件是否已处理
        if h.isEventProcessed(event.ID) {
            return nil
        }

        // 2. 处理事件
        if err := h.processEvent(event); err != nil {
            return err
        }

        // 3. 标记事件已处理
        return h.markEventProcessed(event.ID)
    }
    ```

43. **如何使用Go实现一个简单的服务注册与发现？**
    - 要求：提供基于etcd或Consul的Go代码示例。

    **答案：**
    基于etcd实现服务注册与发现：

    1. **服务注册中心**：
    ```go
    // 1. 服务注册中心
    type ServiceRegistry struct {
        client     *clientv3.Client
        leaseID    clientv3.LeaseID
        cancelFunc context.CancelFunc
    }

    func NewServiceRegistry(endpoints []string) (*ServiceRegistry, error) {
        client, err := clientv3.New(clientv3.Config{
            Endpoints:   endpoints,
            DialTimeout: 5 * time.Second,
        })
        if err != nil {
            return nil, err
        }

        return &ServiceRegistry{
            client: client,
        }, nil
    }

    // 2. 注册服务
    func (r *ServiceRegistry) Register(serviceID, serviceName, address string) error {
        // 创建租约
        lease, err := r.client.Grant(context.Background(), 10)
        if err != nil {
            return err
        }
        r.leaseID = lease.ID

        // 注册服务
        key := fmt.Sprintf("/services/%s/%s", serviceName, serviceID)
        value := address
        _, err = r.client.Put(context.Background(), key, value, clientv3.WithLease(r.leaseID))
        if err != nil {
            return err
        }

        // 自动续租
        ctx, cancel := context.WithCancel(context.Background())
        r.cancelFunc = cancel
        go r.keepAlive(ctx)

        return nil
    }

    // 3. 服务发现
    func (r *ServiceRegistry) Discover(serviceName string) ([]string, error) {
        key := fmt.Sprintf("/services/%s", serviceName)
        resp, err := r.client.Get(context.Background(), key, clientv3.WithPrefix())
        if err != nil {
            return nil, err
        }

        var addresses []string
        for _, kv := range resp.Kvs {
            addresses = append(addresses, string(kv.Value))
        }
        return addresses, nil
    }

    // 4. 自动续租
    func (r *ServiceRegistry) keepAlive(ctx context.Context) {
        keepAliveCh, err := r.client.KeepAlive(ctx, r.leaseID)
        if err != nil {
            return
        }

        for {
            select {
            case _, ok := <-keepAliveCh:
                if !ok {
                    return
                }
            case <-ctx.Done():
                return
            }
        }
    }

    // 5. 注销服务
    func (r *ServiceRegistry) Unregister() error {
        if r.cancelFunc != nil {
            r.cancelFunc()
        }
        if r.leaseID != 0 {
            _, err := r.client.Revoke(context.Background(), r.leaseID)
            return err
        }
        return nil
    }
    ```

    2. **服务注册与发现的使用示例**：
    ```go
    func main() {
        // 1. 创建服务注册中心
        registry, err := NewServiceRegistry([]string{"localhost:2379"})
        if err != nil {
            log.Fatal(err)
        }
        defer registry.Unregister()

        // 2. 注册服务
        err = registry.Register("service-1", "user-service", "localhost:8080")
        if err != nil {
            log.Fatal(err)
        }

        // 3. 服务发现
        addresses, err := registry.Discover("user-service")
        if err != nil {
            log.Fatal(err)
        }

        // 4. 使用发现的服务地址
        for _, addr := range addresses {
            log.Printf("发现服务: %s", addr)
        }
    }
    ```

---

### 7. Docker使用经验
#### 基础题
44. **Docker的核心概念有哪些？容器与镜像的区别是什么？**
    - 要求：解释Image、Container、Dockerfile的概念及关系。

    **答案：**
    Docker的核心概念和组件：

    1. **核心概念**：
    ```
    Image（镜像）：
    - 只读的模板，包含运行应用所需的所有文件和配置
    - 分层存储结构，每一层都可以被复用
    - 通过Dockerfile构建

    Container（容器）：
    - 镜像的运行实例
    - 包含可写层，存储运行时产生的数据
    - 相互隔离，拥有独立的网络和存储空间

    Dockerfile：
    - 用于构建镜像的文本文件
    - 包含构建指令和配置信息
    - 支持多阶段构建
    ```

    2. **镜像与容器的区别**：
    ```
    镜像：
    - 静态的，不可修改
    - 可以创建多个容器
    - 存储在本地仓库
    - 占用空间较小

    容器：
    - 动态的，可以修改
    - 基于镜像创建
    - 运行时状态
    - 包含可写层，占用空间较大
    ```

45. **如何编写一个高效的Dockerfile？**
    - 要求：提供一个Go应用的Dockerfile，说明多阶段构建的优点。

    **答案：**
    编写高效的Dockerfile的关键点：

    1. **基础Dockerfile示例**：
    ```dockerfile
    # 第一阶段：构建
    FROM golang:1.21-alpine AS builder

    # 设置工作目录
    WORKDIR /app

    # 复制依赖文件
    COPY go.mod go.sum ./
    RUN go mod download

    # 复制源代码
    COPY . .

    # 构建应用
    RUN CGO_ENABLED=0 GOOS=linux go build -o main .

    # 第二阶段：运行
    FROM alpine:latest

    # 安装必要的系统工具
    RUN apk --no-cache add ca-certificates tzdata

    # 设置时区
    ENV TZ=Asia/Shanghai

    # 创建非root用户
    RUN adduser -D -g '' appuser

    # 设置工作目录
    WORKDIR /app

    # 从构建阶段复制二进制文件
    COPY --from=builder /app/main .

    # 切换到非root用户
    USER appuser

    # 暴露端口
    EXPOSE 8080

    # 启动应用
    CMD ["./main"]
    ```

    2. **多阶段构建的优点**：
    - 减小最终镜像大小
    - 分离构建环境和运行环境
    - 提高安全性
    - 优化构建缓存

    3. **最佳实践**：
    ```dockerfile
    # 1. 使用官方基础镜像
    FROM golang:1.21-alpine

    # 2. 设置构建参数
    ARG VERSION=1.0.0
    ARG BUILD_DATE

    # 3. 设置环境变量
    ENV GO111MODULE=on \
        CGO_ENABLED=0 \
        GOOS=linux

    # 4. 使用.dockerignore排除不需要的文件
    # .dockerignore
    .git
    .gitignore
    README.md
    Dockerfile
    *.md

    # 5. 优化构建缓存
    COPY go.mod go.sum ./
    RUN go mod download

    # 6. 复制源代码
    COPY . .

    # 7. 构建应用
    RUN go build -ldflags="-w -s" -o main .

    # 8. 使用多阶段构建
    FROM alpine:latest
    COPY --from=builder /app/main .
    ```

46. **Docker Compose有什么用途？如何使用？**
    - 要求：提供一个简单的Docker Compose配置文件，部署Go应用和数据库。

    **答案：**
    Docker Compose用于定义和运行多容器应用：

    1. **基本配置文件**：
    ```yaml
    version: '3.8'

    services:
      # Go应用服务
      app:
        build:
          context: .
          dockerfile: Dockerfile
        ports:
          - "8080:8080"
        environment:
          - DB_HOST=db
          - DB_PORT=5432
          - DB_USER=postgres
          - DB_PASSWORD=secret
        depends_on:
          - db
        networks:
          - app-network
        volumes:
          - ./logs:/app/logs

      # PostgreSQL数据库
      db:
        image: postgres:14-alpine
        environment:
          - POSTGRES_USER=postgres
          - POSTGRES_PASSWORD=secret
          - POSTGRES_DB=myapp
        volumes:
          - postgres-data:/var/lib/postgresql/data
        networks:
          - app-network
        ports:
          - "5432:5432"

      # Redis缓存
      redis:
        image: redis:alpine
        ports:
          - "6379:6379"
        networks:
          - app-network
        volumes:
          - redis-data:/data

    networks:
      app-network:
        driver: bridge

    volumes:
      postgres-data:
      redis-data:
    ```

    2. **常用命令**：
    ```bash
    # 启动服务
    docker-compose up -d

    # 查看服务状态
    docker-compose ps

    # 查看服务日志
    docker-compose logs -f

    # 停止服务
    docker-compose down

    # 重新构建服务
    docker-compose up -d --build
    ```

    3. **环境变量配置**：
    ```yaml
    # .env文件
    DB_HOST=db
    DB_PORT=5432
    DB_USER=postgres
    DB_PASSWORD=secret
    REDIS_HOST=redis
    REDIS_PORT=6379
    ```

#### 进阶题
47. **如何优化Docker镜像的体积？**
    - 要求：介绍使用alpine镜像、多阶段构建、清理缓存等方法。

    **答案：**
    Docker镜像优化策略：

    1. **使用轻量级基础镜像**：
    ```dockerfile
    # 使用alpine作为基础镜像
    FROM golang:1.21-alpine AS builder

    # 安装必要的构建工具
    RUN apk add --no-cache git gcc musl-dev

    # 构建应用
    WORKDIR /app
    COPY . .
    RUN go build -ldflags="-w -s" -o main .

    # 使用scratch作为运行环境
    FROM scratch
    COPY --from=builder /app/main /main
    CMD ["/main"]
    ```

    2. **多阶段构建优化**：
    ```dockerfile
    # 构建阶段
    FROM golang:1.21-alpine AS builder
    WORKDIR /app
    COPY go.mod go.sum ./
    RUN go mod download
    COPY . .
    RUN CGO_ENABLED=0 GOOS=linux go build -ldflags="-w -s" -o main .

    # 运行阶段
    FROM alpine:latest
    RUN apk --no-cache add ca-certificates
    COPY --from=builder /app/main .
    CMD ["/main"]
    ```

    3. **清理构建缓存**：
    ```dockerfile
    # 清理apt缓存
    RUN apt-get update && \
        apt-get install -y package && \
        rm -rf /var/lib/apt/lists/*

    # 清理npm缓存
    RUN npm install && \
        npm cache clean --force

    # 清理yarn缓存
    RUN yarn install && \
        yarn cache clean
    ```

48. **在生产环境中如何监控和管理Docker容器？**
    - 要求：讨论Prometheus、Grafana、Docker Stats等工具的用法。

    **答案：**
    Docker容器监控和管理方案：

    1. **使用Prometheus监控**：
    ```yaml
    # prometheus.yml
    global:
      scrape_interval: 15s

    scrape_configs:
      - job_name: 'docker'
        static_configs:
          - targets: ['localhost:9323']

      - job_name: 'node-exporter'
        static_configs:
          - targets: ['node-exporter:9100']
    ```

    2. **Grafana仪表板配置**：
    ```json
    {
      "dashboard": {
        "panels": [
          {
            "title": "容器CPU使用率",
            "type": "graph",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "rate(container_cpu_usage_seconds_total{container_name=~\"$container\"}[5m])"
              }
            ]
          },
          {
            "title": "容器内存使用",
            "type": "graph",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "container_memory_usage_bytes{container_name=~\"$container\"}"
              }
            ]
          }
        ]
      }
    }
    ```

    3. **Docker Stats API使用**：
    ```go
    // 获取容器统计信息
    func GetContainerStats(containerID string) (*types.Stats, error) {
        ctx := context.Background()
        cli, err := client.NewClientWithOpts(client.FromEnv)
        if err != nil {
            return nil, err
        }

        stats, err := cli.ContainerStats(ctx, containerID, false)
        if err != nil {
            return nil, err
        }

        var statsData types.Stats
        if err := json.NewDecoder(stats.Body).Decode(&statsData); err != nil {
            return nil, err
        }

        return &statsData, nil
    }
    ```

49. **Docker容器化部署中如何处理日志管理？**
    - 要求：说明日志驱动、集中式日志收集（如ELK）的实现。

    **答案：**
    Docker日志管理方案：

    1. **配置日志驱动**：
    ```json
    // daemon.json
    {
      "log-driver": "json-file",
      "log-opts": {
        "max-size": "10m",
        "max-file": "3"
      }
    }
    ```

    2. **使用ELK收集日志**：
    ```yaml
    # docker-compose.yml
    version: '3.8'

    services:
      app:
        image: myapp:latest
        logging:
          driver: "json-file"
          options:
            max-size: "10m"
            max-file: "3"
        labels:
          - "logging=elk"

      filebeat:
        image: docker.elastic.co/beats/filebeat:7.14.0
        volumes:
          - /var/lib/docker/containers:/var/lib/docker/containers:ro
          - /var/run/docker.sock:/var/run/docker.sock:ro
        configs:
          - source: filebeat_config
            target: /usr/share/filebeat/filebeat.yml

      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
        environment:
          - discovery.type=single-node
        ports:
          - "9200:9200"

      kibana:
        image: docker.elastic.co/kibana/kibana:7.14.0
        ports:
          - "5601:5601"
        depends_on:
          - elasticsearch

    configs:
      filebeat_config:
        content: |
          filebeat.inputs:
          - type: container
            paths:
              - '/var/lib/docker/containers/*/*.log'

          output.elasticsearch:
            hosts: ["elasticsearch:9200"]
    ```

    3. **日志收集器实现**：
    ```go
    // 日志收集器
    type LogCollector struct {
        client *elasticsearch.Client
        index  string
    }

    func (c *LogCollector) CollectLogs(containerID string) error {
        // 1. 获取容器日志
        logs, err := c.getContainerLogs(containerID)
        if err != nil {
            return err
        }

        // 2. 解析日志
        logEntries := c.parseLogs(logs)

        // 3. 发送到Elasticsearch
        for _, entry := range logEntries {
            _, err := c.client.Index().
                Index(c.index).
                Document(entry).
                Do(context.Background())
            if err != nil {
                return err
            }
        }

        return nil
    }

    func (c *LogCollector) parseLogs(logs []byte) []LogEntry {
        var entries []LogEntry
        // 解析日志内容
        // ...
        return entries
    }
    ```



